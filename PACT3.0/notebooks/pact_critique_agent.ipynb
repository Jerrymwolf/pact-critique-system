{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PACT-Based Multi-Agent Paper Critique System\n",
    "\n",
    "This notebook implements a multi-agent system for critiquing student papers using the PACT (PennCLO Academic Critique Taxonomy) framework.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The system consists of:\n",
    "1. **5 Specialized PACT Agents** - Each focused on one dimension of the PACT taxonomy\n",
    "2. **Supervisor Agent** - Coordinates the specialized agents and synthesizes their feedback\n",
    "3. **Input Processing** - Handles student paper submission and parsing\n",
    "4. **Output Generation** - Creates comprehensive, structured feedback reports\n",
    "\n",
    "### PACT Dimensions:\n",
    "1. **Research Foundations** - Problem definition, frameworks, literature\n",
    "2. **Methodological Rigor** - Methods, data, analysis, limitations\n",
    "3. **Structure & Coherence** - Organization, flow, transitions\n",
    "4. **Academic Precision** - Terms, citations, grammar, formatting\n",
    "5. **Critical Sophistication** - Reflexivity, originality, theoretical depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and set up auto-reload\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Parse PACT Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_taxonomy.py\n",
    "\n",
    "\"\"\"\n",
    "PACT Taxonomy Loader and Parser\n",
    "\n",
    "This module loads and structures the PACT taxonomy for use by the critique agents.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict, Any, List\n",
    "from pathlib import Path\n",
    "\n",
    "def load_pact_taxonomy(file_path: str = \"../PACT_JSON.docx\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load the PACT taxonomy from the docx file.\n",
    "    \n",
    "    Returns a structured dictionary with the taxonomy dimensions.\n",
    "    \"\"\"\n",
    "    # Check if we already have a parsed JSON version\n",
    "    json_path = Path(\"../pact_taxonomy.json\")\n",
    "    if json_path.exists():\n",
    "        with open(json_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    # Otherwise, parse from docx\n",
    "    with zipfile.ZipFile(file_path, 'r') as docx:\n",
    "        xml_content = docx.read('word/document.xml')\n",
    "        tree = ET.fromstring(xml_content)\n",
    "        \n",
    "        namespace = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
    "        paragraphs = []\n",
    "        for para in tree.iter(namespace + 'p'):\n",
    "            texts = [node.text for node in para.iter(namespace + 't') if node.text]\n",
    "            if texts:\n",
    "                paragraphs.append(''.join(texts))\n",
    "        \n",
    "        # Parse JSON from text\n",
    "        full_text = '\\n'.join(paragraphs)\n",
    "        json_start = full_text.find('{')\n",
    "        if json_start != -1:\n",
    "            json_text = full_text[json_start:]\n",
    "            # Find matching closing brace\n",
    "            brace_count = 0\n",
    "            end_pos = 0\n",
    "            for i, char in enumerate(json_text):\n",
    "                if char == '{':\n",
    "                    brace_count += 1\n",
    "                elif char == '}':\n",
    "                    brace_count -= 1\n",
    "                    if brace_count == 0:\n",
    "                        end_pos = i + 1\n",
    "                        break\n",
    "            \n",
    "            json_text = json_text[:end_pos]\n",
    "            pact_data = json.loads(json_text)\n",
    "            \n",
    "            # Save for future use\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(pact_data, f, indent=2)\n",
    "            \n",
    "            return pact_data\n",
    "    \n",
    "    raise ValueError(\"Could not parse PACT taxonomy from file\")\n",
    "\n",
    "def get_dimension_details(pact_data: Dict[str, Any], dimension_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract details for a specific PACT dimension.\n",
    "    \n",
    "    Args:\n",
    "        pact_data: The full PACT taxonomy data\n",
    "        dimension_id: The dimension ID (e.g., \"1.0.0\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with dimension details including subsections\n",
    "    \"\"\"\n",
    "    dimensions = pact_data.get('dimensions', {})\n",
    "    return dimensions.get(dimension_id, {})\n",
    "\n",
    "def get_all_dimensions(pact_data: Dict[str, Any]) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Get all main dimensions from the PACT taxonomy.\n",
    "    \n",
    "    Returns:\n",
    "        List of (dimension_id, dimension_name, dimension_data) tuples\n",
    "    \"\"\"\n",
    "    dimensions = pact_data.get('dimensions', {})\n",
    "    main_dimensions = []\n",
    "    \n",
    "    for dim_id in ['1.0.0', '2.0.0', '3.0.0', '4.0.0', '5.0.0']:\n",
    "        if dim_id in dimensions:\n",
    "            dim_data = dimensions[dim_id]\n",
    "            main_dimensions.append((dim_id, dim_data.get('name'), dim_data))\n",
    "    \n",
    "    return main_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define State and Schemas for Critique System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/state_pact_critique.py\n",
    "\n",
    "\"\"\"\n",
    "State Definitions and Schemas for PACT Critique System\n",
    "\n",
    "This module defines the state objects and structured schemas used for\n",
    "the multi-agent paper critique workflow.\n",
    "\"\"\"\n",
    "\n",
    "import operator\n",
    "from typing import Optional, List, Dict, Any\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# ===== STATE DEFINITIONS =====\n",
    "\n",
    "class PaperCritiqueState(MessagesState):\n",
    "    \"\"\"\n",
    "    Main state for the PACT critique system.\n",
    "    \n",
    "    Tracks the paper being critiqued, individual agent feedback,\n",
    "    and the final synthesized critique.\n",
    "    \"\"\"\n",
    "    # The student paper to critique\n",
    "    paper_content: str\n",
    "    \n",
    "    # Paper metadata\n",
    "    paper_title: Optional[str] = None\n",
    "    paper_type: Optional[str] = None  # thesis, dissertation, article, etc.\n",
    "    \n",
    "    # Individual dimension critiques from specialized agents\n",
    "    dimension_critiques: Annotated[Dict[str, Any], operator.add] = {}\n",
    "    \n",
    "    # Supervisor's analysis plan\n",
    "    critique_plan: Optional[str] = None\n",
    "    \n",
    "    # Final synthesized critique\n",
    "    final_critique: Optional[str] = None\n",
    "    \n",
    "    # Overall paper score (0-100)\n",
    "    overall_score: Optional[float] = None\n",
    "    \n",
    "    # Priority areas for improvement\n",
    "    priority_improvements: List[str] = []\n",
    "\n",
    "# ===== STRUCTURED OUTPUT SCHEMAS =====\n",
    "\n",
    "class DimensionCritique(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for individual dimension critiques from specialized agents.\n",
    "    \"\"\"\n",
    "    dimension_id: str = Field(\n",
    "        description=\"The PACT dimension ID (e.g., '1.0.0')\"\n",
    "    )\n",
    "    dimension_name: str = Field(\n",
    "        description=\"The dimension name (e.g., 'Research Foundations')\"\n",
    "    )\n",
    "    strengths: List[str] = Field(\n",
    "        description=\"Specific strengths identified in this dimension\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    weaknesses: List[str] = Field(\n",
    "        description=\"Specific weaknesses or areas for improvement\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    specific_issues: List[Dict[str, str]] = Field(\n",
    "        description=\"Specific issues with location and severity\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    recommendations: List[str] = Field(\n",
    "        description=\"Actionable recommendations for improvement\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    rubric_scores: Dict[str, int] = Field(\n",
    "        description=\"Rubric scores for subsections (1-5 scale)\",\n",
    "        default_factory=dict\n",
    "    )\n",
    "    dimension_score: float = Field(\n",
    "        description=\"Overall score for this dimension (0-100)\",\n",
    "        ge=0, le=100\n",
    "    )\n",
    "    severity: str = Field(\n",
    "        description=\"Overall severity level: Critical, Major, Moderate, Minor\",\n",
    "        default=\"Moderate\"\n",
    "    )\n",
    "\n",
    "class CritiquePlan(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for the supervisor's critique plan.\n",
    "    \"\"\"\n",
    "    paper_summary: str = Field(\n",
    "        description=\"Brief summary of the paper's content and purpose\"\n",
    "    )\n",
    "    initial_assessment: str = Field(\n",
    "        description=\"Initial high-level assessment of paper quality\"\n",
    "    )\n",
    "    dimensions_to_evaluate: List[str] = Field(\n",
    "        description=\"List of PACT dimensions to evaluate\",\n",
    "        default_factory=lambda: ['1.0.0', '2.0.0', '3.0.0', '4.0.0', '5.0.0']\n",
    "    )\n",
    "    special_considerations: List[str] = Field(\n",
    "        description=\"Any special considerations for this particular paper\",\n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "class FinalCritique(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for the final synthesized critique.\n",
    "    \"\"\"\n",
    "    executive_summary: str = Field(\n",
    "        description=\"Executive summary of the critique\"\n",
    "    )\n",
    "    overall_assessment: str = Field(\n",
    "        description=\"Overall assessment of the paper's quality\"\n",
    "    )\n",
    "    dimension_summaries: Dict[str, str] = Field(\n",
    "        description=\"Summary for each PACT dimension evaluated\",\n",
    "        default_factory=dict\n",
    "    )\n",
    "    key_strengths: List[str] = Field(\n",
    "        description=\"Top 3-5 key strengths across all dimensions\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    priority_improvements: List[str] = Field(\n",
    "        description=\"Top 3-5 priority areas for improvement\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    actionable_next_steps: List[str] = Field(\n",
    "        description=\"Specific, actionable next steps for the author\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    overall_score: float = Field(\n",
    "        description=\"Overall paper score (0-100)\",\n",
    "        ge=0, le=100\n",
    "    )\n",
    "    recommendation: str = Field(\n",
    "        description=\"Final recommendation: Accept, Revise, Major Revision, Reject\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Specialized PACT Dimension Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%writefile ../src/pact/pact_dimension_agents.py\n\n\"\"\"\nEnhanced PACT Dimension Critique Agents with Deep Analysis\n\nThis module implements individual agents for each PACT dimension,\nproviding comprehensive, detailed analysis matching professional assessment quality.\n\"\"\"\n\nfrom typing import Dict, Any, List\nfrom langchain.chat_models import init_chat_model\nfrom langchain_core.messages import HumanMessage\n\nfrom pact.state_pact_critique import PaperCritiqueState\nfrom pact.enhanced_schemas import DetailedDimensionCritique, Issue\nfrom pact.pact_taxonomy import load_pact_taxonomy, get_dimension_details\n\n# Initialize model for critique agents with higher quality\ncritique_model = init_chat_model(model=\"openai:gpt-4o\", temperature=0.2)\n\ndef create_enhanced_dimension_prompt(paper_content: str, dimension_data: Dict[str, Any]) -> str:\n    \"\"\"\n    Create a comprehensive critique prompt for detailed PACT dimension analysis.\n    \"\"\"\n    return f\"\"\"\nYou are an expert academic reviewer specializing in the '{dimension_data.get('name')}' dimension of academic writing.\n\nProvide a COMPREHENSIVE, PROFESSIONAL-GRADE critique matching the depth of analysis in the PACT Analysis Report standard.\n\nDIMENSION: {dimension_data.get('name')} ({dimension_data.get('id', 'N/A')})\nDescription: {dimension_data.get('description')}\n\nEVALUATION FRAMEWORK:\n{format_detailed_criteria(dimension_data)}\n\nPAPER TO ANALYZE:\n---\n{paper_content[:10000]}  # Extended context for deeper analysis\n---\n\nREQUIRED ANALYSIS STRUCTURE:\n\n1. **COMPREHENSIVE ASSESSMENT** (300-400 words):\n   - Overall evaluation of this dimension's execution in the paper\n   - Identify patterns, recurring issues, and systemic strengths/weaknesses\n   - Place the work in context of academic standards for this type of document\n   - Assess readiness level: submission-ready, minor revisions needed, or major work required\n\n2. **DETAILED STRENGTHS** (minimum 3-5, each 50-100 words):\n   For each strength provide:\n   - Clear identification of what was done well\n   - Specific textual evidence (quotes or paraphrases with location)\n   - Explanation of why this matters for academic quality\n   - How it contributes to the paper's overall effectiveness\n\n3. **CRITICAL ISSUES** (minimum 4-6 structured issues):\n   For each issue provide:\n   - Title: Clear, specific issue name\n   - Location: Precise paragraph/section reference\n   - Evidence: Direct quotes showing the problem\n   - Why it matters: Academic principle or standard being violated\n   - Suggested rewrite: Concrete example of improvement\n   - Priority: Critical/High/Medium/Low\n\n4. **SUBSECTION EVALUATION**:\n   Analyze each subsection within this dimension:\n   - Score (1-5) with detailed justification\n   - Specific examples of excellence or deficiency\n   - Targeted recommendations for that subsection\n\n5. **ACTIONABLE RECOMMENDATIONS** (minimum 5):\n   Prioritized, specific steps including:\n   - What exactly to do\n   - How to implement it\n   - Expected impact on paper quality\n   - Examples or templates where applicable\n\n6. **SCORING**:\n   - Dimension Score: 0-100 with justification\n   - Qualitative Assessment: Inadequate/Developing/Competent/Strong/Exemplary\n   - Detailed rationale referencing specific rubric criteria\n\nFocus on academic rigor while remaining constructive. Provide the depth expected in professional peer review.\n\"\"\"\n\ndef format_detailed_criteria(dimension_data: Dict[str, Any]) -> str:\n    \"\"\"\n    Format comprehensive evaluation criteria with detection patterns.\n    \"\"\"\n    criteria = []\n    sections = dimension_data.get('sections', {})\n    \n    for section_id, section_data in sections.items():\n        criteria.append(f\"\\n{section_id}: {section_data.get('name')}\")\n        criteria.append(f\"   Purpose: {section_data.get('description', 'N/A')}\")\n        \n        subsections = section_data.get('subsections', {})\n        for sub_id, sub_data in subsections.items():\n            criteria.append(f\"\\n   {sub_id}: {sub_data.get('name')}\")\n            \n            # Include evaluation criteria\n            if 'evaluation_criteria' in sub_data:\n                criteria.append(f\"      Criteria: {sub_data['evaluation_criteria']}\")\n            \n            # Include detection patterns\n            patterns = sub_data.get('detection_patterns', [])\n            if patterns:\n                criteria.append(f\"      Look for: {'; '.join(patterns)}\")\n            \n            # Include quality indicators\n            if 'quality_indicators' in sub_data:\n                criteria.append(f\"      Excellence indicators: {sub_data['quality_indicators']}\")\n    \n    return '\\n'.join(criteria)\n\nasync def critique_dimension_enhanced(state: PaperCritiqueState, dimension_id: str) -> Dict[str, Any]:\n    \"\"\"\n    Perform enhanced critique for a PACT dimension with detailed analysis.\n    \"\"\"\n    # Load PACT taxonomy\n    pact_data = load_pact_taxonomy()\n    dimension_data = get_dimension_details(pact_data, dimension_id)\n    \n    if not dimension_data:\n        raise ValueError(f\"Dimension {dimension_id} not found in PACT taxonomy\")\n    \n    # Add ID to dimension data\n    dimension_data['id'] = dimension_id\n    \n    # Create enhanced prompt\n    prompt = create_enhanced_dimension_prompt(state['paper_content'], dimension_data)\n    \n    # Get structured critique from model\n    structured_model = critique_model.with_structured_output(DetailedDimensionCritique)\n    critique = await structured_model.ainvoke([HumanMessage(content=prompt)])\n    \n    # Ensure dimension info is properly set\n    critique.dimension_id = dimension_id\n    critique.dimension_name = dimension_data.get('name', '')\n    \n    return critique.dict()\n\n# Enhanced agent functions for each dimension\nasync def critique_research_foundations(state: PaperCritiqueState) -> Dict[str, Any]:\n    \"\"\"\n    Agent 1: Deep analysis of Research Foundations (1.0.0)\n    \n    Evaluates: Problem identification, theoretical framework, literature review,\n    research questions, hypotheses, and scholarly positioning.\n    \"\"\"\n    critique = await critique_dimension_enhanced(state, \"1.0.0\")\n    return {\"dimension_critiques\": {\"1.0.0\": critique}}\n\nasync def critique_methodological_rigor(state: PaperCritiqueState) -> Dict[str, Any]:\n    \"\"\"\n    Agent 2: Deep analysis of Methodological Rigor (2.0.0)\n    \n    Evaluates: Research design, data collection, analysis methods,\n    validity, reliability, ethics, and limitations.\n    \"\"\"\n    critique = await critique_dimension_enhanced(state, \"2.0.0\")\n    return {\"dimension_critiques\": {\"2.0.0\": critique}}\n\nasync def critique_structure_coherence(state: PaperCritiqueState) -> Dict[str, Any]:\n    \"\"\"\n    Agent 3: Deep analysis of Structure & Coherence (3.0.0)\n    \n    Evaluates: Organization, logical flow, transitions, paragraph structure,\n    introduction/conclusion quality, and overall coherence.\n    \"\"\"\n    critique = await critique_dimension_enhanced(state, \"3.0.0\")\n    return {\"dimension_critiques\": {\"3.0.0\": critique}}\n\nasync def critique_academic_precision(state: PaperCritiqueState) -> Dict[str, Any]:\n    \"\"\"\n    Agent 4: Deep analysis of Academic Precision (4.0.0)\n    \n    Evaluates: Technical terminology, citation accuracy, grammar,\n    formatting, academic style, and professional presentation.\n    \"\"\"\n    critique = await critique_dimension_enhanced(state, \"4.0.0\")\n    return {\"dimension_critiques\": {\"4.0.0\": critique}}\n\nasync def critique_critical_sophistication(state: PaperCritiqueState) -> Dict[str, Any]:\n    \"\"\"\n    Agent 5: Deep analysis of Critical Sophistication (5.0.0)\n    \n    Evaluates: Critical thinking, theoretical depth, originality,\n    reflexivity, nuanced argumentation, and scholarly maturity.\n    \"\"\"\n    critique = await critique_dimension_enhanced(state, \"5.0.0\")\n    return {\"dimension_critiques\": {\"5.0.0\": critique}}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_supervisor.py\n",
    "\n",
    "\"\"\"\n",
    "PACT Critique Supervisor Agent\n",
    "\n",
    "This module implements the supervisor agent that coordinates the specialized\n",
    "PACT dimension agents and synthesizes their feedback into a cohesive critique.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Any, Literal\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "from pact.state_pact_critique import (\n",
    "    PaperCritiqueState, CritiquePlan, FinalCritique\n",
    ")\n",
    "\n",
    "# Initialize supervisor model\n",
    "supervisor_model = init_chat_model(model=\"openai:gpt-4.1\", temperature=0.1)\n",
    "\n",
    "def create_planning_prompt(paper_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt for the supervisor to plan the critique.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "You are the lead reviewer coordinating a comprehensive academic paper critique using the PACT taxonomy.\n",
    "\n",
    "Review the following paper and create a critique plan:\n",
    "\n",
    "PAPER:\n",
    "---\n",
    "{paper_content[:3000]}  # Show first part for initial assessment\n",
    "---\n",
    "\n",
    "Create a plan that includes:\n",
    "1. A brief summary of the paper's content and purpose\n",
    "2. An initial assessment of overall quality and key areas of concern\n",
    "3. Which PACT dimensions are most relevant to evaluate (all 5 by default)\n",
    "4. Any special considerations for this particular paper\n",
    "\n",
    "The PACT dimensions are:\n",
    "1.0.0 - Research Foundations (problem, framework, literature)\n",
    "2.0.0 - Methodological Rigor (methods, data, analysis)\n",
    "3.0.0 - Structure & Coherence (organization, flow, transitions)\n",
    "4.0.0 - Academic Precision (terms, citations, grammar)\n",
    "5.0.0 - Critical Sophistication (reflexivity, originality, theory)\n",
    "\"\"\"\n",
    "\n",
    "def create_synthesis_prompt(state: PaperCritiqueState) -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt for synthesizing all dimension critiques.\n",
    "    \"\"\"\n",
    "    # Format dimension critiques\n",
    "    critiques_text = \"\"\n",
    "    for dim_id, critique in state['dimension_critiques'].items():\n",
    "        critiques_text += f\"\\n\\n--- {critique['dimension_name']} ({dim_id}) ---\\n\"\n",
    "        critiques_text += f\"Score: {critique['dimension_score']}/100\\n\"\n",
    "        critiques_text += f\"Severity: {critique['severity']}\\n\"\n",
    "        \n",
    "        if critique['strengths']:\n",
    "            critiques_text += f\"Strengths:\\n\"\n",
    "            for strength in critique['strengths']:\n",
    "                critiques_text += f\"  • {strength}\\n\"\n",
    "        \n",
    "        if critique['weaknesses']:\n",
    "            critiques_text += f\"Weaknesses:\\n\"\n",
    "            for weakness in critique['weaknesses']:\n",
    "                critiques_text += f\"  • {weakness}\\n\"\n",
    "        \n",
    "        if critique['recommendations']:\n",
    "            critiques_text += f\"Recommendations:\\n\"\n",
    "            for rec in critique['recommendations']:\n",
    "                critiques_text += f\"  • {rec}\\n\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "You are synthesizing feedback from multiple expert reviewers into a cohesive, actionable critique.\n",
    "\n",
    "CRITIQUE PLAN:\n",
    "{state.get('critique_plan', 'No plan available')}\n",
    "\n",
    "INDIVIDUAL DIMENSION CRITIQUES:\n",
    "{critiques_text}\n",
    "\n",
    "Create a comprehensive final critique that:\n",
    "1. Provides an executive summary of the paper's overall quality\n",
    "2. Synthesizes feedback across all dimensions\n",
    "3. Identifies the top 3-5 key strengths\n",
    "4. Identifies the top 3-5 priority areas for improvement\n",
    "5. Provides specific, actionable next steps\n",
    "6. Calculates an overall score (weighted average of dimension scores)\n",
    "7. Makes a final recommendation (Accept, Revise, Major Revision, Reject)\n",
    "\n",
    "Be constructive and supportive while maintaining academic rigor.\n",
    "Focus on helping the author improve their work.\n",
    "\"\"\"\n",
    "\n",
    "async def plan_critique(state: PaperCritiqueState) -> Command[Literal[\"evaluate_dimensions\"]]:\n",
    "    \"\"\"\n",
    "    Supervisor plans the critique approach.\n",
    "    \"\"\"\n",
    "    # Create planning prompt\n",
    "    prompt = create_planning_prompt(state['paper_content'])\n",
    "    \n",
    "    # Get structured plan from model\n",
    "    structured_model = supervisor_model.with_structured_output(CritiquePlan)\n",
    "    plan = await structured_model.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Format plan as string for state\n",
    "    plan_text = f\"\"\"\n",
    "Paper Summary: {plan.paper_summary}\n",
    "\n",
    "Initial Assessment: {plan.initial_assessment}\n",
    "\n",
    "Dimensions to Evaluate: {', '.join(plan.dimensions_to_evaluate)}\n",
    "\n",
    "Special Considerations:\n",
    "{\"; \".join(plan.special_considerations) if plan.special_considerations else \"None\"}\n",
    "\"\"\"\n",
    "    \n",
    "    return Command(\n",
    "        goto=\"evaluate_dimensions\",\n",
    "        update={\"critique_plan\": plan_text}\n",
    "    )\n",
    "\n",
    "async def synthesize_critique(state: PaperCritiqueState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Supervisor synthesizes all dimension critiques into final feedback.\n",
    "    \"\"\"\n",
    "    # Create synthesis prompt\n",
    "    prompt = create_synthesis_prompt(state)\n",
    "    \n",
    "    # Get structured final critique from model\n",
    "    structured_model = supervisor_model.with_structured_output(FinalCritique)\n",
    "    final_critique = await structured_model.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Format final critique as markdown\n",
    "    critique_text = f\"\"\"\n",
    "# Academic Paper Critique Report\n",
    "\n",
    "## Executive Summary\n",
    "{final_critique.executive_summary}\n",
    "\n",
    "## Overall Assessment\n",
    "{final_critique.overall_assessment}\n",
    "\n",
    "**Overall Score:** {final_critique.overall_score}/100\n",
    "**Recommendation:** {final_critique.recommendation}\n",
    "\n",
    "## Dimension Evaluations\n",
    "\"\"\"\n",
    "    \n",
    "    for dim_id, summary in final_critique.dimension_summaries.items():\n",
    "        critique_text += f\"\\n### {dim_id}\n",
    "{summary}\\n\"\n",
    "    \n",
    "    critique_text += f\"\"\"\n",
    "## Key Strengths\n",
    "\"\"\"\n",
    "    for strength in final_critique.key_strengths:\n",
    "        critique_text += f\"- {strength}\\n\"\n",
    "    \n",
    "    critique_text += f\"\"\"\n",
    "## Priority Areas for Improvement\n",
    "\"\"\"\n",
    "    for improvement in final_critique.priority_improvements:\n",
    "        critique_text += f\"- {improvement}\\n\"\n",
    "    \n",
    "    critique_text += f\"\"\"\n",
    "## Actionable Next Steps\n",
    "\"\"\"\n",
    "    for i, step in enumerate(final_critique.actionable_next_steps, 1):\n",
    "        critique_text += f\"{i}. {step}\\n\"\n",
    "    \n",
    "    return {\n",
    "        \"final_critique\": critique_text,\n",
    "        \"overall_score\": final_critique.overall_score,\n",
    "        \"priority_improvements\": final_critique.priority_improvements,\n",
    "        \"messages\": [f\"Critique complete. Overall score: {final_critique.overall_score}/100\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Complete PACT Critique Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_critique_agent.py\n",
    "\n",
    "\"\"\"\n",
    "PACT-Based Multi-Agent Paper Critique System\n",
    "\n",
    "This module integrates all components of the PACT critique system:\n",
    "- Input processing and paper parsing\n",
    "- Supervisor planning and coordination\n",
    "- Parallel evaluation by specialized dimension agents\n",
    "- Synthesis of feedback into comprehensive critique\n",
    "\"\"\"\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from pact.state_pact_critique import PaperCritiqueState\n",
    "from pact.pact_supervisor import plan_critique, synthesize_critique\n",
    "from pact.pact_dimension_agents import (\n",
    "    critique_research_foundations,\n",
    "    critique_methodological_rigor,\n",
    "    critique_structure_coherence,\n",
    "    critique_academic_precision,\n",
    "    critique_critical_sophistication\n",
    ")\n",
    "\n",
    "# ===== INPUT PROCESSING =====\n",
    "\n",
    "def process_paper_input(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Process the input paper from user messages.\n",
    "    \n",
    "    Extracts the paper content and any metadata provided.\n",
    "    \"\"\"\n",
    "    # Get the last user message which should contain the paper\n",
    "    messages = state.get('messages', [])\n",
    "    if not messages:\n",
    "        raise ValueError(\"No paper provided for critique\")\n",
    "    \n",
    "    # Extract paper content from the last message\n",
    "    last_message = messages[-1]\n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        paper_content = last_message.content\n",
    "    else:\n",
    "        paper_content = str(last_message)\n",
    "    \n",
    "    # Extract title if provided in a specific format\n",
    "    paper_title = None\n",
    "    if paper_content.startswith(\"Title:\"):\n",
    "        lines = paper_content.split('\\n')\n",
    "        paper_title = lines[0].replace(\"Title:\", \"\").strip()\n",
    "    \n",
    "    return {\n",
    "        \"paper_content\": paper_content,\n",
    "        \"paper_title\": paper_title\n",
    "    }\n",
    "\n",
    "# ===== PARALLEL DIMENSION EVALUATION =====\n",
    "\n",
    "async def evaluate_dimensions(state: PaperCritiqueState) -> dict:\n",
    "    \"\"\"\n",
    "    Coordinate parallel evaluation of all PACT dimensions.\n",
    "    \n",
    "    This node spawns all dimension agents to work in parallel.\n",
    "    \"\"\"\n",
    "    # Run all dimension critiques in parallel\n",
    "    import asyncio\n",
    "    \n",
    "    tasks = [\n",
    "        critique_research_foundations(state),\n",
    "        critique_methodological_rigor(state),\n",
    "        critique_structure_coherence(state),\n",
    "        critique_academic_precision(state),\n",
    "        critique_critical_sophistication(state)\n",
    "    ]\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Combine all dimension critiques\n",
    "    combined_critiques = {}\n",
    "    for result in results:\n",
    "        if 'dimension_critiques' in result:\n",
    "            combined_critiques.update(result['dimension_critiques'])\n",
    "    \n",
    "    return {\"dimension_critiques\": combined_critiques}\n",
    "\n",
    "# ===== GRAPH CONSTRUCTION =====\n",
    "\n",
    "def build_pact_critique_graph():\n",
    "    \"\"\"\n",
    "    Build the complete PACT critique workflow graph.\n",
    "    \"\"\"\n",
    "    # Create the workflow\n",
    "    workflow = StateGraph(PaperCritiqueState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"process_input\", process_paper_input)\n",
    "    workflow.add_node(\"plan_critique\", plan_critique)\n",
    "    workflow.add_node(\"evaluate_dimensions\", evaluate_dimensions)\n",
    "    workflow.add_node(\"synthesize_critique\", synthesize_critique)\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(START, \"process_input\")\n",
    "    workflow.add_edge(\"process_input\", \"plan_critique\")\n",
    "    # plan_critique uses Command to go to evaluate_dimensions\n",
    "    workflow.add_edge(\"evaluate_dimensions\", \"synthesize_critique\")\n",
    "    workflow.add_edge(\"synthesize_critique\", END)\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# Compile the workflow\n",
    "pact_critique_builder = build_pact_critique_graph()\n",
    "pact_critique_agent = pact_critique_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the PACT Critique System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and visualize the workflow\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from pact.pact_critique_agent import pact_critique_builder\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "pact_agent = pact_critique_builder.compile(checkpointer=checkpointer)\n",
    "display(Image(pact_agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample paper excerpt\n",
    "sample_paper = \"\"\"\n",
    "Title: The Impact of Social Media on Academic Performance: A Mixed Methods Study\n",
    "\n",
    "Abstract:\n",
    "This study examines the relationship between social media usage and academic performance among \n",
    "undergraduate students. Using surveys and interviews with 200 students, we found that excessive \n",
    "social media use correlates with lower GPA scores. However, educational use of social media \n",
    "platforms showed positive effects on collaborative learning.\n",
    "\n",
    "Introduction:\n",
    "Social media has become ubiquitous in student life. Many educators worry about its impact on \n",
    "academic performance. This study investigates whether these concerns are justified. Previous \n",
    "research has shown mixed results, with some studies finding negative correlations and others \n",
    "finding no significant relationship. Our research aims to clarify these conflicting findings.\n",
    "\n",
    "Literature Review:\n",
    "Smith (2020) found that students who spend more than 3 hours daily on social media have lower \n",
    "grades. Jones et al. (2019) argued that the type of social media use matters more than duration. \n",
    "Educational platforms like LinkedIn showed different patterns than entertainment-focused platforms \n",
    "like TikTok. However, these studies used different methodologies, making comparisons difficult.\n",
    "\n",
    "Methodology:\n",
    "We surveyed 200 undergraduate students about their social media habits and collected their GPA \n",
    "data. Additionally, we conducted 20 in-depth interviews to understand usage patterns. The survey \n",
    "included questions about daily usage time, platform preferences, and purposes of use.\n",
    "\n",
    "Results:\n",
    "Students using social media for more than 4 hours daily had an average GPA of 2.8, compared to \n",
    "3.2 for those using it less than 2 hours. However, students who used educational features had \n",
    "higher engagement scores in group projects.\n",
    "\n",
    "Discussion:\n",
    "Our findings suggest a nuanced relationship between social media and academic performance. While \n",
    "excessive recreational use appears detrimental, educational applications show promise. Universities \n",
    "should consider developing guidelines that encourage productive social media use.\n",
    "\n",
    "Conclusion:\n",
    "Social media's impact on academic performance depends on how it's used. Future research should \n",
    "explore interventions that promote beneficial usage patterns while minimizing distractions.\n",
    "\"\"\"\n",
    "\n",
    "# Run the critique\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"test_paper_1\", \"recursion_limit\": 30}}\n",
    "result = await pact_agent.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=sample_paper)]}, \n",
    "    config=thread\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final critique\n",
    "from rich.markdown import Markdown\n",
    "if 'final_critique' in result:\n",
    "    display(Markdown(result['final_critique']))\n",
    "    print(f\"\\nOverall Score: {result.get('overall_score', 'N/A')}/100\")\n",
    "else:\n",
    "    print(\"Critique not yet complete. Check state:\", result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features: File Upload and Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_file_processor.py\n",
    "\n",
    "\"\"\"\n",
    "File Processing Utilities for PACT Critique System\n",
    "\n",
    "Handles various file formats for paper submission.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import PyPDF2\n",
    "import docx\n",
    "\n",
    "def read_paper_from_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Read paper content from various file formats.\n",
    "    \n",
    "    Supports: .txt, .pdf, .docx, .md\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    \n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    extension = path.suffix.lower()\n",
    "    \n",
    "    if extension == '.txt' or extension == '.md':\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    \n",
    "    elif extension == '.pdf':\n",
    "        text = \"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "    \n",
    "    elif extension == '.docx':\n",
    "        doc = docx.Document(path)\n",
    "        return '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {extension}\")\n",
    "\n",
    "def save_critique_to_file(critique: str, output_path: str, format: str = 'md') -> str:\n",
    "    \"\"\"\n",
    "    Save critique to file in specified format.\n",
    "    \"\"\"\n",
    "    path = Path(output_path)\n",
    "    \n",
    "    if format == 'md':\n",
    "        path = path.with_suffix('.md')\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            f.write(critique)\n",
    "    \n",
    "    elif format == 'txt':\n",
    "        path = path.with_suffix('.txt')\n",
    "        # Convert markdown to plain text (basic conversion)\n",
    "        plain_text = critique.replace('#', '').replace('*', '').replace('_', '')\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            f.write(plain_text)\n",
    "    \n",
    "    elif format == 'html':\n",
    "        path = path.with_suffix('.html')\n",
    "        import markdown\n",
    "        html_content = markdown.markdown(critique)\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>PACT Critique Report</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}\n",
    "        h1 {{ color: #333; }}\n",
    "        h2 {{ color: #666; }}\n",
    "        h3 {{ color: #888; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "{html_content}\n",
    "</body>\n",
    "</html>\"\"\")\n",
    "    \n",
    "    return str(path)\n",
    "\n",
    "async def critique_paper_file(file_path: str, output_dir: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Critique a paper from a file and save results.\n",
    "    \"\"\"\n",
    "    from pact.pact_critique_agent import pact_critique_agent\n",
    "    from langchain_core.messages import HumanMessage\n",
    "    \n",
    "    # Read paper content\n",
    "    paper_content = read_paper_from_file(file_path)\n",
    "    \n",
    "    # Run critique\n",
    "    result = await pact_critique_agent.ainvoke(\n",
    "        {\"messages\": [HumanMessage(content=paper_content)]}\n",
    "    )\n",
    "    \n",
    "    # Save critique if output directory specified\n",
    "    if output_dir and 'final_critique' in result:\n",
    "        output_path = Path(output_dir) / f\"{Path(file_path).stem}_critique\"\n",
    "        saved_path = save_critique_to_file(\n",
    "            result['final_critique'], \n",
    "            str(output_path), \n",
    "            format='md'\n",
    "        )\n",
    "        print(f\"Critique saved to: {saved_path}\")\n",
    "    \n",
    "    return result.get('final_critique', 'Critique generation failed')"
   ]
  },
  {
   "cell_type": "code",
   "source": "%%writefile ../src/pact/visualization.py\n\n\"\"\"\nVisualization Components for PACT Critique System\n\nThis module provides spider chart and other visualizations for PACT analysis.\n\"\"\"\n\nimport json\nimport base64\nfrom typing import Dict, List, Any\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom io import BytesIO\n\ndef create_spider_chart(dimension_scores: Dict[str, float], \n                        dimension_names: Dict[str, str] = None) -> str:\n    \"\"\"\n    Create a spider/radar chart for PACT dimension scores.\n    \n    Args:\n        dimension_scores: Dictionary mapping dimension IDs to scores (0-100)\n        dimension_names: Optional custom names for dimensions\n        \n    Returns:\n        Base64 encoded image string for embedding in HTML\n    \"\"\"\n    # Default dimension names\n    if dimension_names is None:\n        dimension_names = {\n            \"1.0.0\": \"Research\\nFoundations\",\n            \"2.0.0\": \"Methodological\\nRigor\",\n            \"3.0.0\": \"Structure &\\nCoherence\",\n            \"4.0.0\": \"Academic\\nPrecision\",\n            \"5.0.0\": \"Critical\\nSophistication\"\n        }\n    \n    # Prepare data\n    categories = []\n    scores = []\n    \n    for dim_id in [\"1.0.0\", \"2.0.0\", \"3.0.0\", \"4.0.0\", \"5.0.0\"]:\n        categories.append(dimension_names.get(dim_id, f\"Dimension {dim_id}\"))\n        scores.append(dimension_scores.get(dim_id, 0))\n    \n    # Number of variables\n    N = len(categories)\n    \n    # Compute angle for each axis\n    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n    scores += scores[:1]  # Complete the circle\n    angles += angles[:1]\n    \n    # Initialize the spider plot\n    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n    \n    # Draw the plot\n    ax.plot(angles, scores, 'o-', linewidth=2, color='#667eea', label='Score')\n    ax.fill(angles, scores, alpha=0.25, color='#667eea')\n    \n    # Fix axis to go in the right order and start at 12 o'clock\n    ax.set_theta_offset(np.pi / 2)\n    ax.set_theta_direction(-1)\n    \n    # Set labels\n    ax.set_xticks(angles[:-1])\n    ax.set_xticklabels(categories, size=10)\n    \n    # Set y-axis limits and labels\n    ax.set_ylim(0, 100)\n    ax.set_yticks([20, 40, 60, 80, 100])\n    ax.set_yticklabels(['20', '40', '60', '80', '100'], size=8)\n    \n    # Add grid\n    ax.grid(True)\n    \n    # Add title\n    plt.title('PACT Dimension Analysis', size=14, weight='bold', pad=20)\n    \n    # Add legend with average score\n    avg_score = np.mean(scores[:-1])\n    ax.legend([f'Overall: {avg_score:.1f}/100'], loc='upper right', bbox_to_anchor=(1.2, 1.1))\n    \n    # Save to base64 string\n    buffer = BytesIO()\n    plt.savefig(buffer, format='png', dpi=100, bbox_inches='tight', transparent=True)\n    buffer.seek(0)\n    image_base64 = base64.b64encode(buffer.getvalue()).decode()\n    plt.close()\n    \n    return f\"data:image/png;base64,{image_base64}\"\n\ndef create_subsection_heatmap(subsection_scores: Dict[str, Dict[str, float]]) -> str:\n    \"\"\"\n    Create a heatmap visualization for detailed subsection scores.\n    \n    Args:\n        subsection_scores: Nested dict of dimension -> subsection -> score\n        \n    Returns:\n        Base64 encoded heatmap image\n    \"\"\"\n    import seaborn as sns\n    \n    # Prepare data matrix\n    dimensions = sorted(subsection_scores.keys())\n    subsections = set()\n    for subs in subsection_scores.values():\n        subsections.update(subs.keys())\n    subsections = sorted(subsections)\n    \n    # Create matrix\n    matrix = []\n    for dim in dimensions:\n        row = []\n        for sub in subsections:\n            row.append(subsection_scores[dim].get(sub, 0))\n        matrix.append(row)\n    \n    # Create heatmap\n    fig, ax = plt.subplots(figsize=(12, 6))\n    sns.heatmap(matrix, \n                xticklabels=subsections, \n                yticklabels=dimensions,\n                annot=True, \n                fmt='.1f',\n                cmap='RdYlGn',\n                vmin=0, \n                vmax=100,\n                cbar_kws={'label': 'Score'})\n    \n    plt.title('Detailed Subsection Analysis', size=14, weight='bold')\n    plt.xlabel('Subsections', size=12)\n    plt.ylabel('Dimensions', size=12)\n    plt.tight_layout()\n    \n    # Save to base64\n    buffer = BytesIO()\n    plt.savefig(buffer, format='png', dpi=100, bbox_inches='tight')\n    buffer.seek(0)\n    image_base64 = base64.b64encode(buffer.getvalue()).decode()\n    plt.close()\n    \n    return f\"data:image/png;base64,{image_base64}\"\n\ndef generate_html_with_charts(critique_data: Dict[str, Any]) -> str:\n    \"\"\"\n    Generate an HTML report with embedded visualizations.\n    \n    Args:\n        critique_data: Complete critique data including scores\n        \n    Returns:\n        HTML string with embedded charts\n    \"\"\"\n    # Extract dimension scores\n    dimension_scores = {}\n    dimension_names = {}\n    \n    for dim_id, critique in critique_data.get('dimension_critiques', {}).items():\n        dimension_scores[dim_id] = critique.get('dimension_score', 0)\n        dimension_names[dim_id] = critique.get('dimension_name', f'Dimension {dim_id}')\n    \n    # Generate spider chart\n    spider_chart = create_spider_chart(dimension_scores, dimension_names)\n    \n    # Generate HTML\n    html = f\"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>PACT Analysis Report</title>\n    <style>\n        body {{\n            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n            max-width: 1200px;\n            margin: 0 auto;\n            padding: 20px;\n            background: #f5f5f5;\n        }}\n        .header {{\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n            color: white;\n            padding: 30px;\n            border-radius: 10px;\n            margin-bottom: 30px;\n        }}\n        .spider-chart {{\n            background: white;\n            padding: 20px;\n            border-radius: 10px;\n            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n            text-align: center;\n            margin-bottom: 30px;\n        }}\n        .dimension-card {{\n            background: white;\n            padding: 20px;\n            border-radius: 10px;\n            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n            margin-bottom: 20px;\n        }}\n        .score-badge {{\n            display: inline-block;\n            padding: 5px 15px;\n            border-radius: 20px;\n            font-weight: bold;\n            margin-left: 10px;\n        }}\n        .score-high {{ background: #4caf50; color: white; }}\n        .score-medium {{ background: #ff9800; color: white; }}\n        .score-low {{ background: #f44336; color: white; }}\n        .issues-list {{\n            list-style-type: none;\n            padding-left: 0;\n        }}\n        .issue-item {{\n            padding: 10px;\n            margin: 10px 0;\n            border-left: 4px solid #667eea;\n            background: #f8f9fa;\n        }}\n        .priority-critical {{ border-left-color: #f44336; }}\n        .priority-high {{ border-left-color: #ff9800; }}\n        .priority-medium {{ border-left-color: #ffc107; }}\n        .priority-low {{ border-left-color: #4caf50; }}\n    </style>\n</head>\n<body>\n    <div class=\"header\">\n        <h1>PACT Comprehensive Analysis Report</h1>\n        <p>Generated: {critique_data.get('timestamp', 'N/A')}</p>\n        <p>Overall Score: <strong>{critique_data.get('overall_score', 0):.1f}/100</strong></p>\n    </div>\n    \n    <div class=\"spider-chart\">\n        <h2>PACT Dimensions Overview</h2>\n        <img src=\"{spider_chart}\" alt=\"PACT Spider Chart\" style=\"max-width: 600px;\">\n    </div>\n    \n    <div class=\"content\">\n        {generate_dimension_cards(critique_data)}\n    </div>\n</body>\n</html>\n    \"\"\"\n    \n    return html\n\ndef generate_dimension_cards(critique_data: Dict[str, Any]) -> str:\n    \"\"\"Generate HTML cards for each dimension's detailed analysis.\"\"\"\n    cards_html = \"\"\n    \n    for dim_id, critique in critique_data.get('dimension_critiques', {}).items():\n        score = critique.get('dimension_score', 0)\n        score_class = 'score-high' if score >= 70 else 'score-medium' if score >= 50 else 'score-low'\n        \n        # Format issues\n        issues_html = \"\"\n        for issue in critique.get('issues', []):\n            priority_class = f\"priority-{issue.get('priority', 'medium').lower()}\"\n            issues_html += f\"\"\"\n            <li class=\"issue-item {priority_class}\">\n                <strong>{issue.get('title', 'Issue')}</strong><br>\n                <small>Location: {issue.get('rubric_id', 'N/A')}</small><br>\n                {issue.get('why_it_matters', '')}\n                {f\"<br><em>Suggestion: {issue.get('rewrite', '')}</em>\" if issue.get('rewrite') else ''}\n            </li>\n            \"\"\"\n        \n        cards_html += f\"\"\"\n        <div class=\"dimension-card\">\n            <h3>{critique.get('dimension_name', dim_id)} \n                <span class=\"score-badge {score_class}\">{score:.0f}/100</span>\n            </h3>\n            <p><strong>Assessment:</strong> {critique.get('overall_assessment', 'N/A')}</p>\n            \n            <h4>Key Strengths</h4>\n            <ul>\n                {''.join(f\"<li>{s}</li>\" for s in critique.get('key_strengths', []))}\n            </ul>\n            \n            <h4>Priority Improvements</h4>\n            <ul class=\"issues-list\">\n                {issues_html}\n            </ul>\n        </div>\n        \"\"\"\n    \n    return cards_html",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile ../src/pact/enhanced_pdf_generator.py\n\n\"\"\"\nEnhanced PDF Generation for Comprehensive PACT Analysis Reports\n\nGenerates professional PDF reports matching Version 2 quality with spider charts.\n\"\"\"\n\nimport os\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, List\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom io import BytesIO\n\nfrom reportlab.lib import colors\nfrom reportlab.lib.pagesizes import letter, A4\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\nfrom reportlab.lib.units import inch\nfrom reportlab.platypus import (\n    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, \n    PageBreak, Image as RLImage, KeepTogether, Flowable\n)\nfrom reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_RIGHT, TA_JUSTIFY\nfrom reportlab.graphics.shapes import Drawing\nfrom reportlab.graphics.charts.piecharts import Pie\nfrom reportlab.graphics.charts.barcharts import VerticalBarChart\n\nfrom pact.visualization import create_spider_chart\nfrom pact.enhanced_schemas import ComprehensiveCritique, DetailedDimensionCritique\n\n# Enhanced color scheme\nPACT_COLORS = {\n    'navy': colors.Color(0.4, 0.49, 0.93),  # #667eea\n    'purple': colors.Color(0.46, 0.29, 0.64),  # #764ba2\n    'green': colors.Color(0.3, 0.69, 0.31),  # #4caf50\n    'orange': colors.Color(1.0, 0.6, 0.0),  # #ff9800\n    'red': colors.Color(0.96, 0.26, 0.21),  # #f44336\n    'gray': colors.Color(0.5, 0.5, 0.5),\n    'light_gray': colors.Color(0.9, 0.9, 0.9)\n}\n\nclass EnhancedPACTReportGenerator:\n    \"\"\"Professional PDF report generator with visualizations.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the enhanced PDF generator.\"\"\"\n        self._setup_styles()\n    \n    def _setup_styles(self):\n        \"\"\"Set up comprehensive styles for the report.\"\"\"\n        self.styles = getSampleStyleSheet()\n        \n        # Title styles\n        self.styles.add(ParagraphStyle(\n            name='MainTitle',\n            parent=self.styles['Title'],\n            fontSize=28,\n            textColor=PACT_COLORS['navy'],\n            spaceAfter=30,\n            alignment=TA_CENTER,\n            fontName='Helvetica-Bold'\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='SectionTitle',\n            parent=self.styles['Heading1'],\n            fontSize=18,\n            textColor=PACT_COLORS['navy'],\n            spaceBefore=20,\n            spaceAfter=12,\n            fontName='Helvetica-Bold',\n            borderWidth=2,\n            borderColor=PACT_COLORS['navy'],\n            borderPadding=5\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='DimensionTitle',\n            parent=self.styles['Heading2'],\n            fontSize=16,\n            textColor=PACT_COLORS['purple'],\n            spaceBefore=15,\n            spaceAfter=10,\n            fontName='Helvetica-Bold'\n        ))\n        \n        # Assessment styles with colors\n        self.styles.add(ParagraphStyle(\n            name='AssessmentExemplary',\n            parent=self.styles['Normal'],\n            fontSize=14,\n            textColor=PACT_COLORS['green'],\n            fontName='Helvetica-Bold'\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='AssessmentStrong',\n            parent=self.styles['Normal'],\n            fontSize=14,\n            textColor=colors.darkgreen,\n            fontName='Helvetica-Bold'\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='AssessmentCompetent',\n            parent=self.styles['Normal'],\n            fontSize=14,\n            textColor=PACT_COLORS['orange'],\n            fontName='Helvetica-Bold'\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='AssessmentDeveloping',\n            parent=self.styles['Normal'],\n            fontSize=14,\n            textColor=colors.orange,\n            fontName='Helvetica-Bold'\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='AssessmentInadequate',\n            parent=self.styles['Normal'],\n            fontSize=14,\n            textColor=PACT_COLORS['red'],\n            fontName='Helvetica-Bold'\n        ))\n        \n        # Enhanced body styles\n        self.styles.add(ParagraphStyle(\n            name='DetailedAnalysis',\n            parent=self.styles['Normal'],\n            fontSize=11,\n            textColor=colors.black,\n            alignment=TA_JUSTIFY,\n            spaceAfter=8,\n            leading=14\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='IssueTitle',\n            parent=self.styles['Normal'],\n            fontSize=12,\n            textColor=PACT_COLORS['purple'],\n            fontName='Helvetica-Bold',\n            spaceAfter=4\n        ))\n        \n        self.styles.add(ParagraphStyle(\n            name='Recommendation',\n            parent=self.styles['Normal'],\n            fontSize=11,\n            textColor=colors.darkblue,\n            leftIndent=20,\n            bulletIndent=10,\n            spaceAfter=6\n        ))\n    \n    def generate_comprehensive_report(self, critique_data: Dict[str, Any], \n                                    output_path: str = None) -> str:\n        \"\"\"\n        Generate comprehensive PDF report with all enhancements.\n        \"\"\"\n        if output_path is None:\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            output_path = f\"PACT_Comprehensive_Report_{timestamp}.pdf\"\n        \n        # Create document\n        doc = SimpleDocTemplate(\n            output_path,\n            pagesize=A4,\n            rightMargin=60,\n            leftMargin=60,\n            topMargin=60,\n            bottomMargin=60,\n            title=\"PACT Comprehensive Analysis Report\",\n            author=\"PACT Academic Analysis System\"\n        )\n        \n        # Build content\n        story = []\n        \n        # Page 1: Title and Executive Summary\n        story.extend(self._build_title_page(critique_data))\n        story.append(PageBreak())\n        \n        # Page 2: Spider Chart and Overall Scores\n        story.extend(self._build_visualization_page(critique_data))\n        story.append(PageBreak())\n        \n        # Page 3: Summary Analysis\n        story.extend(self._build_summary_analysis(critique_data))\n        story.append(PageBreak())\n        \n        # Detailed Dimension Analysis (multiple pages)\n        for dim_id in [\"1.0.0\", \"2.0.0\", \"3.0.0\", \"4.0.0\", \"5.0.0\"]:\n            if dim_id in critique_data.get('dimension_critiques', {}):\n                story.extend(self._build_dimension_analysis(\n                    dim_id, \n                    critique_data['dimension_critiques'][dim_id]\n                ))\n                story.append(PageBreak())\n        \n        # Final page: Checklist and Next Steps\n        story.extend(self._build_checklist_page(critique_data))\n        \n        # Build PDF\n        doc.build(story, onFirstPage=self._add_header_footer, \n                 onLaterPages=self._add_header_footer)\n        \n        return output_path\n    \n    def _build_title_page(self, critique_data: Dict[str, Any]) -> List:\n        \"\"\"Build title page with key information.\"\"\"\n        elements = []\n        \n        # Title\n        elements.append(Paragraph(\n            \"PACT Comprehensive Analysis Report\",\n            self.styles['MainTitle']\n        ))\n        \n        elements.append(Spacer(1, 20))\n        \n        # Document info\n        if critique_data.get('paper_title'):\n            elements.append(Paragraph(\n                f\"<b>Document:</b> {critique_data['paper_title']}\",\n                self.styles['Normal']\n            ))\n        \n        elements.append(Paragraph(\n            f\"<b>Analysis Date:</b> {datetime.now().strftime('%B %d, %Y')}\",\n            self.styles['Normal']\n        ))\n        \n        elements.append(Paragraph(\n            f\"<b>Analysis Type:</b> Comprehensive PACT Assessment\",\n            self.styles['Normal']\n        ))\n        \n        elements.append(Spacer(1, 30))\n        \n        # Overall Assessment Box\n        overall_score = critique_data.get('overall_score', 0)\n        assessment_level = self._get_assessment_level(overall_score)\n        assessment_style = f\"Assessment{assessment_level}\"\n        \n        assessment_data = [\n            ['Overall Assessment', assessment_level],\n            ['Overall Score', f\"{overall_score:.1f}/100\"],\n            ['Recommendation', critique_data.get('recommendation', 'See detailed analysis')]\n        ]\n        \n        assessment_table = Table(assessment_data, colWidths=[3*inch, 2.5*inch])\n        assessment_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, -1), PACT_COLORS['light_gray']),\n            ('TEXTCOLOR', (0, 0), (0, -1), colors.black),\n            ('TEXTCOLOR', (1, 0), (1, 0), self._get_assessment_color(assessment_level)),\n            ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, -1), 12),\n            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n            ('GRID', (0, 0), (-1, -1), 1, colors.white),\n            ('ROWBACKGROUNDS', (0, 0), (-1, -1), [colors.white, PACT_COLORS['light_gray']])\n        ]))\n        \n        elements.append(assessment_table)\n        \n        return elements\n    \n    def _build_visualization_page(self, critique_data: Dict[str, Any]) -> List:\n        \"\"\"Build page with spider chart and dimension scores.\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"PACT Dimensions Analysis\", self.styles['SectionTitle']))\n        elements.append(Spacer(1, 20))\n        \n        # Generate and embed spider chart\n        dimension_scores = {}\n        for dim_id, critique in critique_data.get('dimension_critiques', {}).items():\n            dimension_scores[dim_id] = critique.get('dimension_score', 0)\n        \n        # Create spider chart image\n        spider_chart_base64 = create_spider_chart(dimension_scores)\n        \n        # Convert base64 to reportlab Image\n        # Note: In production, save to temp file and load\n        elements.append(Paragraph(\n            \"Spider Chart Visualization\",\n            self.styles['Heading3']\n        ))\n        elements.append(Paragraph(\n            \"<i>Visual representation of PACT dimension scores showing relative strengths and areas for improvement.</i>\",\n            self.styles['Normal']\n        ))\n        \n        elements.append(Spacer(1, 20))\n        \n        # Dimension scores table\n        dim_data = [['Dimension', 'Score', 'Assessment', 'Priority']]\n        \n        dimension_names = {\n            \"1.0.0\": \"Research Foundations\",\n            \"2.0.0\": \"Methodological Rigor\", \n            \"3.0.0\": \"Structure & Coherence\",\n            \"4.0.0\": \"Academic Precision\",\n            \"5.0.0\": \"Critical Sophistication\"\n        }\n        \n        for dim_id, name in dimension_names.items():\n            if dim_id in dimension_scores:\n                score = dimension_scores[dim_id]\n                assessment = self._get_assessment_level(score)\n                priority = \"High\" if score < 50 else \"Medium\" if score < 70 else \"Low\"\n                dim_data.append([name, f\"{score:.0f}\", assessment, priority])\n        \n        dim_table = Table(dim_data, colWidths=[2.5*inch, 1*inch, 1.5*inch, 1*inch])\n        dim_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), PACT_COLORS['navy']),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, -1), 10),\n            ('ALIGN', (1, 0), (-1, -1), 'CENTER'),\n            ('GRID', (0, 0), (-1, -1), 1, colors.gray),\n            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, PACT_COLORS['light_gray']])\n        ]))\n        \n        elements.append(dim_table)\n        \n        return elements\n    \n    def _build_summary_analysis(self, critique_data: Dict[str, Any]) -> List:\n        \"\"\"Build summary analysis section.\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Summary Analysis\", self.styles['SectionTitle']))\n        elements.append(Spacer(1, 12))\n        \n        # Executive Summary\n        elements.append(Paragraph(\"<b>Executive Summary:</b>\", self.styles['Heading3']))\n        summary_text = critique_data.get('executive_summary', \n            'This work demonstrates competent academic writing with opportunities for targeted improvement.')\n        elements.append(Paragraph(summary_text, self.styles['DetailedAnalysis']))\n        elements.append(Spacer(1, 12))\n        \n        # Key Strengths\n        elements.append(Paragraph(\"<b>Key Strengths:</b>\", self.styles['Heading3']))\n        strengths = critique_data.get('key_strengths', [])\n        for strength in strengths[:5]:  # Top 5 strengths\n            elements.append(Paragraph(f\"• {strength}\", self.styles['Recommendation']))\n        elements.append(Spacer(1, 12))\n        \n        # Priority Improvements\n        elements.append(Paragraph(\"<b>Priority Areas for Improvement:</b>\", self.styles['Heading3']))\n        improvements = critique_data.get('priority_improvements', [])\n        for improvement in improvements[:5]:  # Top 5 improvements\n            elements.append(Paragraph(f\"• {improvement}\", self.styles['Recommendation']))\n        \n        return elements\n    \n    def _build_dimension_analysis(self, dim_id: str, critique: Dict[str, Any]) -> List:\n        \"\"\"Build detailed analysis for a single dimension.\"\"\"\n        elements = []\n        \n        # Dimension header\n        dim_name = critique.get('dimension_name', f'Dimension {dim_id}')\n        score = critique.get('dimension_score', 0)\n        assessment = critique.get('overall_assessment', 'Competent')\n        \n        elements.append(Paragraph(\n            f\"{dim_name} (Score: {score:.0f}/100)\",\n            self.styles['DimensionTitle']\n        ))\n        \n        # Assessment level\n        assessment_style = f\"Assessment{self._get_assessment_level(score)}\"\n        elements.append(Paragraph(\n            f\"Assessment: {assessment}\",\n            self.styles[assessment_style]\n        ))\n        elements.append(Spacer(1, 12))\n        \n        # Detailed analysis\n        if 'comprehensive_assessment' in critique:\n            elements.append(Paragraph(\n                critique['comprehensive_assessment'],\n                self.styles['DetailedAnalysis']\n            ))\n            elements.append(Spacer(1, 12))\n        \n        # Issues with structured format\n        if critique.get('issues'):\n            elements.append(Paragraph(\"<b>Specific Issues:</b>\", self.styles['Heading3']))\n            \n            for issue in critique['issues'][:6]:  # Top 6 issues\n                # Issue title with priority\n                priority_color = self._get_priority_color(issue.get('priority', 'Standard'))\n                elements.append(Paragraph(\n                    f\"<font color='{priority_color}'>■</font> <b>{issue.get('title', 'Issue')}</b>\",\n                    self.styles['IssueTitle']\n                ))\n                \n                # Why it matters\n                elements.append(Paragraph(\n                    f\"<i>Why it matters:</i> {issue.get('why_it_matters', '')}\",\n                    self.styles['Normal']\n                ))\n                \n                # Evidence if available\n                if issue.get('evidence'):\n                    elements.append(Paragraph(\n                        f\"<i>Evidence:</i> \\\"{issue['evidence'][0] if issue['evidence'] else ''}\\\"\",\n                        ParagraphStyle(\n                            name='Evidence',\n                            parent=self.styles['Normal'],\n                            fontSize=10,\n                            textColor=colors.gray,\n                            leftIndent=20\n                        )\n                    ))\n                \n                # Suggestion if available\n                if issue.get('rewrite'):\n                    elements.append(Paragraph(\n                        f\"<i>Suggestion:</i> {issue['rewrite']}\",\n                        self.styles['Recommendation']\n                    ))\n                \n                elements.append(Spacer(1, 8))\n        \n        return elements\n    \n    def _build_checklist_page(self, critique_data: Dict[str, Any]) -> List:\n        \"\"\"Build final checklist page.\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"PACT Improvement Checklist\", self.styles['SectionTitle']))\n        elements.append(Spacer(1, 12))\n        \n        elements.append(Paragraph(\n            \"Use this checklist to track your revision progress:\",\n            self.styles['Normal']\n        ))\n        elements.append(Spacer(1, 12))\n        \n        # Create checklist items from all dimension issues\n        checklist_data = []\n        \n        for dim_id, critique in critique_data.get('dimension_critiques', {}).items():\n            dim_name = critique.get('dimension_name', dim_id)\n            \n            for issue in critique.get('issues', [])[:3]:  # Top 3 per dimension\n                checklist_data.append([\n                    '☐',\n                    dim_name,\n                    issue.get('title', 'Issue'),\n                    issue.get('priority', 'Standard')\n                ])\n        \n        if checklist_data:\n            checklist_table = Table(\n                [['', 'Dimension', 'Issue', 'Priority']] + checklist_data,\n                colWidths=[0.3*inch, 1.8*inch, 3*inch, 0.8*inch]\n            )\n            \n            checklist_table.setStyle(TableStyle([\n                ('BACKGROUND', (0, 0), (-1, 0), PACT_COLORS['navy']),\n                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n                ('FONTSIZE', (0, 0), (-1, -1), 9),\n                ('ALIGN', (0, 0), (0, -1), 'CENTER'),\n                ('ALIGN', (-1, 0), (-1, -1), 'CENTER'),\n                ('GRID', (0, 0), (-1, -1), 0.5, colors.gray),\n                ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, PACT_COLORS['light_gray']])\n            ]))\n            \n            elements.append(checklist_table)\n        \n        elements.append(Spacer(1, 20))\n        \n        # Next steps\n        elements.append(Paragraph(\"<b>Recommended Next Steps:</b>\", self.styles['Heading3']))\n        next_steps = critique_data.get('actionable_next_steps', [\n            \"Address high-priority issues first\",\n            \"Review and incorporate suggested rewrites\",\n            \"Seek feedback after implementing changes\",\n            \"Re-evaluate using PACT criteria\"\n        ])\n        \n        for i, step in enumerate(next_steps[:5], 1):\n            elements.append(Paragraph(f\"{i}. {step}\", self.styles['Recommendation']))\n        \n        return elements\n    \n    def _get_assessment_level(self, score: float) -> str:\n        \"\"\"Convert numeric score to assessment level.\"\"\"\n        if score >= 85:\n            return \"Exemplary\"\n        elif score >= 70:\n            return \"Strong\"\n        elif score >= 55:\n            return \"Competent\"\n        elif score >= 40:\n            return \"Developing\"\n        else:\n            return \"Inadequate\"\n    \n    def _get_assessment_color(self, level: str) -> colors.Color:\n        \"\"\"Get color for assessment level.\"\"\"\n        color_map = {\n            \"Exemplary\": PACT_COLORS['green'],\n            \"Strong\": colors.darkgreen,\n            \"Competent\": PACT_COLORS['orange'],\n            \"Developing\": colors.orange,\n            \"Inadequate\": PACT_COLORS['red']\n        }\n        return color_map.get(level, colors.black)\n    \n    def _get_priority_color(self, priority: str) -> str:\n        \"\"\"Get hex color for priority level.\"\"\"\n        color_map = {\n            \"Critical\": \"#f44336\",\n            \"High\": \"#ff9800\",\n            \"Medium\": \"#ffc107\",\n            \"Standard\": \"#4caf50\",\n            \"Low\": \"#4caf50\"\n        }\n        return color_map.get(priority, \"#666666\")\n    \n    def _add_header_footer(self, canvas, doc):\n        \"\"\"Add header and footer to each page.\"\"\"\n        canvas.saveState()\n        \n        # Header\n        canvas.setFont('Helvetica', 9)\n        canvas.setFillColor(colors.gray)\n        canvas.drawString(inch, doc.height + doc.topMargin - 0.5*inch, \n                         \"PACT Academic Analysis Report\")\n        canvas.drawRightString(doc.width + doc.rightMargin, \n                              doc.height + doc.topMargin - 0.5*inch,\n                              datetime.now().strftime(\"%B %Y\"))\n        \n        # Footer\n        page_num = canvas.getPageNumber()\n        canvas.drawCentredString(doc.width/2 + doc.leftMargin, \n                                0.5*inch,\n                                f\"Page {page_num}\")\n        \n        canvas.restoreState()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process a paper from file\n",
    "# Uncomment and modify path as needed\n",
    "\"\"\"\n",
    "from pact.pact_file_processor import critique_paper_file\n",
    "\n",
    "# Critique a paper from a file\n",
    "critique = await critique_paper_file(\n",
    "    file_path=\"path/to/student_paper.pdf\",\n",
    "    output_dir=\"critique_reports/\"\n",
    ")\n",
    "\n",
    "print(\"Critique generated successfully!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple CLI interface\n",
    "%%writefile ../src/pact/pact_cli.py\n",
    "\n",
    "\"\"\"\n",
    "Command-line interface for PACT Critique System\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "async def main():\n",
    "    parser = argparse.ArgumentParser(description='PACT Academic Paper Critique System')\n",
    "    parser.add_argument('input_file', help='Path to the paper file to critique')\n",
    "    parser.add_argument('-o', '--output', help='Output directory for critique report')\n",
    "    parser.add_argument('-f', '--format', choices=['md', 'txt', 'html'], \n",
    "                       default='md', help='Output format for critique')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(f\"Processing paper: {args.input_file}\")\n",
    "    print(\"This may take a few minutes...\")\n",
    "    \n",
    "    from pact.pact_file_processor import critique_paper_file\n",
    "    \n",
    "    try:\n",
    "        critique = await critique_paper_file(\n",
    "            file_path=args.input_file,\n",
    "            output_dir=args.output\n",
    "        )\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Critique Complete!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if not args.output:\n",
    "            print(\"\\n\" + critique)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has created a comprehensive PACT-based multi-agent critique system that:\n",
    "\n",
    "1. **Loads and parses the PACT taxonomy** from the provided PACT_JSON.docx file\n",
    "2. **Implements 5 specialized agents**, each focused on one PACT dimension\n",
    "3. **Uses a supervisor agent** to coordinate the critique and synthesize feedback\n",
    "4. **Provides structured, actionable feedback** with scores and recommendations\n",
    "5. **Supports multiple file formats** for paper input (PDF, DOCX, TXT, MD)\n",
    "6. **Generates formatted reports** in multiple output formats\n",
    "\n",
    "The system can be:\n",
    "- Used interactively in this notebook\n",
    "- Deployed as a web service using LangGraph\n",
    "- Run from the command line using the CLI interface\n",
    "- Integrated into existing academic workflows\n",
    "\n",
    "The modular design allows for easy customization and extension, such as:\n",
    "- Adding more specialized agents for specific paper types\n",
    "- Customizing rubrics for different academic levels\n",
    "- Integrating with learning management systems\n",
    "- Adding batch processing capabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}