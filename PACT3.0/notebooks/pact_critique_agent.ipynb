{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PACT-Based Multi-Agent Paper Critique System\n",
    "\n",
    "This notebook implements a multi-agent system for critiquing student papers using the PACT (PennCLO Academic Critique Taxonomy) framework.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The system consists of:\n",
    "1. **5 Specialized PACT Agents** - Each focused on one dimension of the PACT taxonomy\n",
    "2. **Supervisor Agent** - Coordinates the specialized agents and synthesizes their feedback\n",
    "3. **Input Processing** - Handles student paper submission and parsing\n",
    "4. **Output Generation** - Creates comprehensive, structured feedback reports\n",
    "\n",
    "### PACT Dimensions:\n",
    "1. **Research Foundations** - Problem definition, frameworks, literature\n",
    "2. **Methodological Rigor** - Methods, data, analysis, limitations\n",
    "3. **Structure & Coherence** - Organization, flow, transitions\n",
    "4. **Academic Precision** - Terms, citations, grammar, formatting\n",
    "5. **Critical Sophistication** - Reflexivity, originality, theoretical depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables and set up auto-reload\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Parse PACT Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_taxonomy.py\n",
    "\n",
    "\"\"\"\n",
    "PACT Taxonomy Loader and Parser\n",
    "\n",
    "This module loads and structures the PACT taxonomy for use by the critique agents.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict, Any, List\n",
    "from pathlib import Path\n",
    "\n",
    "def load_pact_taxonomy(file_path: str = \"../PACT_JSON.docx\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load the PACT taxonomy from the docx file.\n",
    "    \n",
    "    Returns a structured dictionary with the taxonomy dimensions.\n",
    "    \"\"\"\n",
    "    # Check if we already have a parsed JSON version\n",
    "    json_path = Path(\"../pact_taxonomy.json\")\n",
    "    if json_path.exists():\n",
    "        with open(json_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    # Otherwise, parse from docx\n",
    "    with zipfile.ZipFile(file_path, 'r') as docx:\n",
    "        xml_content = docx.read('word/document.xml')\n",
    "        tree = ET.fromstring(xml_content)\n",
    "        \n",
    "        namespace = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
    "        paragraphs = []\n",
    "        for para in tree.iter(namespace + 'p'):\n",
    "            texts = [node.text for node in para.iter(namespace + 't') if node.text]\n",
    "            if texts:\n",
    "                paragraphs.append(''.join(texts))\n",
    "        \n",
    "        # Parse JSON from text\n",
    "        full_text = '\\n'.join(paragraphs)\n",
    "        json_start = full_text.find('{')\n",
    "        if json_start != -1:\n",
    "            json_text = full_text[json_start:]\n",
    "            # Find matching closing brace\n",
    "            brace_count = 0\n",
    "            end_pos = 0\n",
    "            for i, char in enumerate(json_text):\n",
    "                if char == '{':\n",
    "                    brace_count += 1\n",
    "                elif char == '}':\n",
    "                    brace_count -= 1\n",
    "                    if brace_count == 0:\n",
    "                        end_pos = i + 1\n",
    "                        break\n",
    "            \n",
    "            json_text = json_text[:end_pos]\n",
    "            pact_data = json.loads(json_text)\n",
    "            \n",
    "            # Save for future use\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(pact_data, f, indent=2)\n",
    "            \n",
    "            return pact_data\n",
    "    \n",
    "    raise ValueError(\"Could not parse PACT taxonomy from file\")\n",
    "\n",
    "def get_dimension_details(pact_data: Dict[str, Any], dimension_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract details for a specific PACT dimension.\n",
    "    \n",
    "    Args:\n",
    "        pact_data: The full PACT taxonomy data\n",
    "        dimension_id: The dimension ID (e.g., \"1.0.0\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with dimension details including subsections\n",
    "    \"\"\"\n",
    "    dimensions = pact_data.get('dimensions', {})\n",
    "    return dimensions.get(dimension_id, {})\n",
    "\n",
    "def get_all_dimensions(pact_data: Dict[str, Any]) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Get all main dimensions from the PACT taxonomy.\n",
    "    \n",
    "    Returns:\n",
    "        List of (dimension_id, dimension_name, dimension_data) tuples\n",
    "    \"\"\"\n",
    "    dimensions = pact_data.get('dimensions', {})\n",
    "    main_dimensions = []\n",
    "    \n",
    "    for dim_id in ['1.0.0', '2.0.0', '3.0.0', '4.0.0', '5.0.0']:\n",
    "        if dim_id in dimensions:\n",
    "            dim_data = dimensions[dim_id]\n",
    "            main_dimensions.append((dim_id, dim_data.get('name'), dim_data))\n",
    "    \n",
    "    return main_dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define State and Schemas for Critique System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/state_pact_critique.py\n",
    "\n",
    "\"\"\"\n",
    "State Definitions and Schemas for PACT Critique System\n",
    "\n",
    "This module defines the state objects and structured schemas used for\n",
    "the multi-agent paper critique workflow.\n",
    "\"\"\"\n",
    "\n",
    "import operator\n",
    "from typing import Optional, List, Dict, Any\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# ===== STATE DEFINITIONS =====\n",
    "\n",
    "class PaperCritiqueState(MessagesState):\n",
    "    \"\"\"\n",
    "    Main state for the PACT critique system.\n",
    "    \n",
    "    Tracks the paper being critiqued, individual agent feedback,\n",
    "    and the final synthesized critique.\n",
    "    \"\"\"\n",
    "    # The student paper to critique\n",
    "    paper_content: str\n",
    "    \n",
    "    # Paper metadata\n",
    "    paper_title: Optional[str] = None\n",
    "    paper_type: Optional[str] = None  # thesis, dissertation, article, etc.\n",
    "    \n",
    "    # Individual dimension critiques from specialized agents\n",
    "    dimension_critiques: Annotated[Dict[str, Any], operator.add] = {}\n",
    "    \n",
    "    # Supervisor's analysis plan\n",
    "    critique_plan: Optional[str] = None\n",
    "    \n",
    "    # Final synthesized critique\n",
    "    final_critique: Optional[str] = None\n",
    "    \n",
    "    # Overall paper score (0-100)\n",
    "    overall_score: Optional[float] = None\n",
    "    \n",
    "    # Priority areas for improvement\n",
    "    priority_improvements: List[str] = []\n",
    "\n",
    "# ===== STRUCTURED OUTPUT SCHEMAS =====\n",
    "\n",
    "class DimensionCritique(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for individual dimension critiques from specialized agents.\n",
    "    \"\"\"\n",
    "    dimension_id: str = Field(\n",
    "        description=\"The PACT dimension ID (e.g., '1.0.0')\"\n",
    "    )\n",
    "    dimension_name: str = Field(\n",
    "        description=\"The dimension name (e.g., 'Research Foundations')\"\n",
    "    )\n",
    "    strengths: List[str] = Field(\n",
    "        description=\"Specific strengths identified in this dimension\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    weaknesses: List[str] = Field(\n",
    "        description=\"Specific weaknesses or areas for improvement\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    specific_issues: List[Dict[str, str]] = Field(\n",
    "        description=\"Specific issues with location and severity\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    recommendations: List[str] = Field(\n",
    "        description=\"Actionable recommendations for improvement\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    rubric_scores: Dict[str, int] = Field(\n",
    "        description=\"Rubric scores for subsections (1-5 scale)\",\n",
    "        default_factory=dict\n",
    "    )\n",
    "    dimension_score: float = Field(\n",
    "        description=\"Overall score for this dimension (0-100)\",\n",
    "        ge=0, le=100\n",
    "    )\n",
    "    severity: str = Field(\n",
    "        description=\"Overall severity level: Critical, Major, Moderate, Minor\",\n",
    "        default=\"Moderate\"\n",
    "    )\n",
    "\n",
    "class CritiquePlan(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for the supervisor's critique plan.\n",
    "    \"\"\"\n",
    "    paper_summary: str = Field(\n",
    "        description=\"Brief summary of the paper's content and purpose\"\n",
    "    )\n",
    "    initial_assessment: str = Field(\n",
    "        description=\"Initial high-level assessment of paper quality\"\n",
    "    )\n",
    "    dimensions_to_evaluate: List[str] = Field(\n",
    "        description=\"List of PACT dimensions to evaluate\",\n",
    "        default_factory=lambda: ['1.0.0', '2.0.0', '3.0.0', '4.0.0', '5.0.0']\n",
    "    )\n",
    "    special_considerations: List[str] = Field(\n",
    "        description=\"Any special considerations for this particular paper\",\n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "class FinalCritique(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for the final synthesized critique.\n",
    "    \"\"\"\n",
    "    executive_summary: str = Field(\n",
    "        description=\"Executive summary of the critique\"\n",
    "    )\n",
    "    overall_assessment: str = Field(\n",
    "        description=\"Overall assessment of the paper's quality\"\n",
    "    )\n",
    "    dimension_summaries: Dict[str, str] = Field(\n",
    "        description=\"Summary for each PACT dimension evaluated\",\n",
    "        default_factory=dict\n",
    "    )\n",
    "    key_strengths: List[str] = Field(\n",
    "        description=\"Top 3-5 key strengths across all dimensions\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    priority_improvements: List[str] = Field(\n",
    "        description=\"Top 3-5 priority areas for improvement\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    actionable_next_steps: List[str] = Field(\n",
    "        description=\"Specific, actionable next steps for the author\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    overall_score: float = Field(\n",
    "        description=\"Overall paper score (0-100)\",\n",
    "        ge=0, le=100\n",
    "    )\n",
    "    recommendation: str = Field(\n",
    "        description=\"Final recommendation: Accept, Revise, Major Revision, Reject\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Specialized PACT Dimension Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_dimension_agents.py\n",
    "\n",
    "\"\"\"\n",
    "Specialized PACT Dimension Critique Agents\n",
    "\n",
    "This module implements individual agents for each PACT dimension,\n",
    "each specialized in evaluating specific aspects of academic writing.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Any\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from pact.state_pact_critique import PaperCritiqueState, DimensionCritique\n",
    "from pact.pact_taxonomy import load_pact_taxonomy, get_dimension_details\n",
    "\n",
    "# Initialize model for critique agents\n",
    "critique_model = init_chat_model(model=\"openai:gpt-4.1\", temperature=0.2)\n",
    "\n",
    "def create_dimension_critique_prompt(paper_content: str, dimension_data: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Create a critique prompt for a specific PACT dimension.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "You are an expert academic reviewer specializing in evaluating the '{dimension_data.get('name')}' dimension of academic papers.\n",
    "\n",
    "Your task is to critique the following paper according to the PACT taxonomy criteria for this dimension.\n",
    "\n",
    "DIMENSION DETAILS:\n",
    "Name: {dimension_data.get('name')}\n",
    "Description: {dimension_data.get('description')}\n",
    "Severity: {dimension_data.get('severity')}\n",
    "\n",
    "EVALUATION CRITERIA:\n",
    "{format_dimension_criteria(dimension_data)}\n",
    "\n",
    "PAPER TO CRITIQUE:\n",
    "---\n",
    "{paper_content[:5000]}  # Truncate for context limits\n",
    "---\n",
    "\n",
    "Please provide a thorough critique focusing on:\n",
    "1. Specific strengths in this dimension\n",
    "2. Specific weaknesses or issues\n",
    "3. Location of issues (paragraph/section references where possible)\n",
    "4. Severity of each issue\n",
    "5. Concrete, actionable recommendations for improvement\n",
    "6. Rubric scores (1-5) for each subsection\n",
    "\n",
    "Be constructive but honest. Focus on helping the author improve their work.\n",
    "\"\"\"\n",
    "\n",
    "def format_dimension_criteria(dimension_data: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Format the evaluation criteria for a dimension.\n",
    "    \"\"\"\n",
    "    criteria = []\n",
    "    sections = dimension_data.get('sections', {})\n",
    "    \n",
    "    for section_id, section_data in sections.items():\n",
    "        criteria.append(f\"\\n{section_id}: {section_data.get('name')}\")\n",
    "        \n",
    "        # Add subsections if available\n",
    "        subsections = section_data.get('subsections', {})\n",
    "        for subsection_id, subsection_data in subsections.items():\n",
    "            criteria.append(f\"  - {subsection_id}: {subsection_data.get('name')}\")\n",
    "            \n",
    "            # Add detection patterns if available\n",
    "            patterns = subsection_data.get('detection_patterns', [])\n",
    "            if patterns:\n",
    "                criteria.append(f\"    Detection patterns: {', '.join(patterns[:3])}\")\n",
    "    \n",
    "    return '\\n'.join(criteria)\n",
    "\n",
    "async def critique_dimension(state: PaperCritiqueState, dimension_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Critique a paper for a specific PACT dimension.\n",
    "    \n",
    "    Args:\n",
    "        state: The current critique state\n",
    "        dimension_id: The PACT dimension to evaluate (e.g., \"1.0.0\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with the dimension critique\n",
    "    \"\"\"\n",
    "    # Load PACT taxonomy\n",
    "    pact_data = load_pact_taxonomy()\n",
    "    dimension_data = get_dimension_details(pact_data, dimension_id)\n",
    "    \n",
    "    if not dimension_data:\n",
    "        raise ValueError(f\"Dimension {dimension_id} not found in PACT taxonomy\")\n",
    "    \n",
    "    # Create critique prompt\n",
    "    prompt = create_dimension_critique_prompt(state['paper_content'], dimension_data)\n",
    "    \n",
    "    # Get structured critique from model\n",
    "    structured_model = critique_model.with_structured_output(DimensionCritique)\n",
    "    critique = await structured_model.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Ensure dimension info is set\n",
    "    critique.dimension_id = dimension_id\n",
    "    critique.dimension_name = dimension_data.get('name', '')\n",
    "    \n",
    "    return critique.dict()\n",
    "\n",
    "# Create specific agent functions for each dimension\n",
    "async def critique_research_foundations(state: PaperCritiqueState) -> Dict[str, Any]:\n",
    "    \"\"\"Agent 1: Critique Research Foundations (1.0.0)\"\"\"\n",
    "    critique = await critique_dimension(state, \"1.0.0\")\n",
    "    return {\"dimension_critiques\": {\"1.0.0\": critique}}\n",
    "\n",
    "async def critique_methodological_rigor(state: PaperCritiqueState) -> Dict[str, Any]:\n",
    "    \"\"\"Agent 2: Critique Methodological Rigor (2.0.0)\"\"\"\n",
    "    critique = await critique_dimension(state, \"2.0.0\")\n",
    "    return {\"dimension_critiques\": {\"2.0.0\": critique}}\n",
    "\n",
    "async def critique_structure_coherence(state: PaperCritiqueState) -> Dict[str, Any]:\n",
    "    \"\"\"Agent 3: Critique Structure & Coherence (3.0.0)\"\"\"\n",
    "    critique = await critique_dimension(state, \"3.0.0\")\n",
    "    return {\"dimension_critiques\": {\"3.0.0\": critique}}\n",
    "\n",
    "async def critique_academic_precision(state: PaperCritiqueState) -> Dict[str, Any]:\n",
    "    \"\"\"Agent 4: Critique Academic Precision (4.0.0)\"\"\"\n",
    "    critique = await critique_dimension(state, \"4.0.0\")\n",
    "    return {\"dimension_critiques\": {\"4.0.0\": critique}}\n",
    "\n",
    "async def critique_critical_sophistication(state: PaperCritiqueState) -> Dict[str, Any]:\n",
    "    \"\"\"Agent 5: Critique Critical Sophistication (5.0.0)\"\"\"\n",
    "    critique = await critique_dimension(state, \"5.0.0\")\n",
    "    return {\"dimension_critiques\": {\"5.0.0\": critique}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_supervisor.py\n",
    "\n",
    "\"\"\"\n",
    "PACT Critique Supervisor Agent\n",
    "\n",
    "This module implements the supervisor agent that coordinates the specialized\n",
    "PACT dimension agents and synthesizes their feedback into a cohesive critique.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Any, Literal\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "from pact.state_pact_critique import (\n",
    "    PaperCritiqueState, CritiquePlan, FinalCritique\n",
    ")\n",
    "\n",
    "# Initialize supervisor model\n",
    "supervisor_model = init_chat_model(model=\"openai:gpt-4.1\", temperature=0.1)\n",
    "\n",
    "def create_planning_prompt(paper_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt for the supervisor to plan the critique.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "You are the lead reviewer coordinating a comprehensive academic paper critique using the PACT taxonomy.\n",
    "\n",
    "Review the following paper and create a critique plan:\n",
    "\n",
    "PAPER:\n",
    "---\n",
    "{paper_content[:3000]}  # Show first part for initial assessment\n",
    "---\n",
    "\n",
    "Create a plan that includes:\n",
    "1. A brief summary of the paper's content and purpose\n",
    "2. An initial assessment of overall quality and key areas of concern\n",
    "3. Which PACT dimensions are most relevant to evaluate (all 5 by default)\n",
    "4. Any special considerations for this particular paper\n",
    "\n",
    "The PACT dimensions are:\n",
    "1.0.0 - Research Foundations (problem, framework, literature)\n",
    "2.0.0 - Methodological Rigor (methods, data, analysis)\n",
    "3.0.0 - Structure & Coherence (organization, flow, transitions)\n",
    "4.0.0 - Academic Precision (terms, citations, grammar)\n",
    "5.0.0 - Critical Sophistication (reflexivity, originality, theory)\n",
    "\"\"\"\n",
    "\n",
    "def create_synthesis_prompt(state: PaperCritiqueState) -> str:\n",
    "    \"\"\"\n",
    "    Create a prompt for synthesizing all dimension critiques.\n",
    "    \"\"\"\n",
    "    # Format dimension critiques\n",
    "    critiques_text = \"\"\n",
    "    for dim_id, critique in state['dimension_critiques'].items():\n",
    "        critiques_text += f\"\\n\\n--- {critique['dimension_name']} ({dim_id}) ---\\n\"\n",
    "        critiques_text += f\"Score: {critique['dimension_score']}/100\\n\"\n",
    "        critiques_text += f\"Severity: {critique['severity']}\\n\"\n",
    "        \n",
    "        if critique['strengths']:\n",
    "            critiques_text += f\"Strengths:\\n\"\n",
    "            for strength in critique['strengths']:\n",
    "                critiques_text += f\"  • {strength}\\n\"\n",
    "        \n",
    "        if critique['weaknesses']:\n",
    "            critiques_text += f\"Weaknesses:\\n\"\n",
    "            for weakness in critique['weaknesses']:\n",
    "                critiques_text += f\"  • {weakness}\\n\"\n",
    "        \n",
    "        if critique['recommendations']:\n",
    "            critiques_text += f\"Recommendations:\\n\"\n",
    "            for rec in critique['recommendations']:\n",
    "                critiques_text += f\"  • {rec}\\n\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "You are synthesizing feedback from multiple expert reviewers into a cohesive, actionable critique.\n",
    "\n",
    "CRITIQUE PLAN:\n",
    "{state.get('critique_plan', 'No plan available')}\n",
    "\n",
    "INDIVIDUAL DIMENSION CRITIQUES:\n",
    "{critiques_text}\n",
    "\n",
    "Create a comprehensive final critique that:\n",
    "1. Provides an executive summary of the paper's overall quality\n",
    "2. Synthesizes feedback across all dimensions\n",
    "3. Identifies the top 3-5 key strengths\n",
    "4. Identifies the top 3-5 priority areas for improvement\n",
    "5. Provides specific, actionable next steps\n",
    "6. Calculates an overall score (weighted average of dimension scores)\n",
    "7. Makes a final recommendation (Accept, Revise, Major Revision, Reject)\n",
    "\n",
    "Be constructive and supportive while maintaining academic rigor.\n",
    "Focus on helping the author improve their work.\n",
    "\"\"\"\n",
    "\n",
    "async def plan_critique(state: PaperCritiqueState) -> Command[Literal[\"evaluate_dimensions\"]]:\n",
    "    \"\"\"\n",
    "    Supervisor plans the critique approach.\n",
    "    \"\"\"\n",
    "    # Create planning prompt\n",
    "    prompt = create_planning_prompt(state['paper_content'])\n",
    "    \n",
    "    # Get structured plan from model\n",
    "    structured_model = supervisor_model.with_structured_output(CritiquePlan)\n",
    "    plan = await structured_model.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Format plan as string for state\n",
    "    plan_text = f\"\"\"\n",
    "Paper Summary: {plan.paper_summary}\n",
    "\n",
    "Initial Assessment: {plan.initial_assessment}\n",
    "\n",
    "Dimensions to Evaluate: {', '.join(plan.dimensions_to_evaluate)}\n",
    "\n",
    "Special Considerations:\n",
    "{\"; \".join(plan.special_considerations) if plan.special_considerations else \"None\"}\n",
    "\"\"\"\n",
    "    \n",
    "    return Command(\n",
    "        goto=\"evaluate_dimensions\",\n",
    "        update={\"critique_plan\": plan_text}\n",
    "    )\n",
    "\n",
    "async def synthesize_critique(state: PaperCritiqueState) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Supervisor synthesizes all dimension critiques into final feedback.\n",
    "    \"\"\"\n",
    "    # Create synthesis prompt\n",
    "    prompt = create_synthesis_prompt(state)\n",
    "    \n",
    "    # Get structured final critique from model\n",
    "    structured_model = supervisor_model.with_structured_output(FinalCritique)\n",
    "    final_critique = await structured_model.ainvoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Format final critique as markdown\n",
    "    critique_text = f\"\"\"\n",
    "# Academic Paper Critique Report\n",
    "\n",
    "## Executive Summary\n",
    "{final_critique.executive_summary}\n",
    "\n",
    "## Overall Assessment\n",
    "{final_critique.overall_assessment}\n",
    "\n",
    "**Overall Score:** {final_critique.overall_score}/100\n",
    "**Recommendation:** {final_critique.recommendation}\n",
    "\n",
    "## Dimension Evaluations\n",
    "\"\"\"\n",
    "    \n",
    "    for dim_id, summary in final_critique.dimension_summaries.items():\n",
    "        critique_text += f\"\\n### {dim_id}\n",
    "{summary}\\n\"\n",
    "    \n",
    "    critique_text += f\"\"\"\n",
    "## Key Strengths\n",
    "\"\"\"\n",
    "    for strength in final_critique.key_strengths:\n",
    "        critique_text += f\"- {strength}\\n\"\n",
    "    \n",
    "    critique_text += f\"\"\"\n",
    "## Priority Areas for Improvement\n",
    "\"\"\"\n",
    "    for improvement in final_critique.priority_improvements:\n",
    "        critique_text += f\"- {improvement}\\n\"\n",
    "    \n",
    "    critique_text += f\"\"\"\n",
    "## Actionable Next Steps\n",
    "\"\"\"\n",
    "    for i, step in enumerate(final_critique.actionable_next_steps, 1):\n",
    "        critique_text += f\"{i}. {step}\\n\"\n",
    "    \n",
    "    return {\n",
    "        \"final_critique\": critique_text,\n",
    "        \"overall_score\": final_critique.overall_score,\n",
    "        \"priority_improvements\": final_critique.priority_improvements,\n",
    "        \"messages\": [f\"Critique complete. Overall score: {final_critique.overall_score}/100\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Complete PACT Critique Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_critique_agent.py\n",
    "\n",
    "\"\"\"\n",
    "PACT-Based Multi-Agent Paper Critique System\n",
    "\n",
    "This module integrates all components of the PACT critique system:\n",
    "- Input processing and paper parsing\n",
    "- Supervisor planning and coordination\n",
    "- Parallel evaluation by specialized dimension agents\n",
    "- Synthesis of feedback into comprehensive critique\n",
    "\"\"\"\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from pact.state_pact_critique import PaperCritiqueState\n",
    "from pact.pact_supervisor import plan_critique, synthesize_critique\n",
    "from pact.pact_dimension_agents import (\n",
    "    critique_research_foundations,\n",
    "    critique_methodological_rigor,\n",
    "    critique_structure_coherence,\n",
    "    critique_academic_precision,\n",
    "    critique_critical_sophistication\n",
    ")\n",
    "\n",
    "# ===== INPUT PROCESSING =====\n",
    "\n",
    "def process_paper_input(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Process the input paper from user messages.\n",
    "    \n",
    "    Extracts the paper content and any metadata provided.\n",
    "    \"\"\"\n",
    "    # Get the last user message which should contain the paper\n",
    "    messages = state.get('messages', [])\n",
    "    if not messages:\n",
    "        raise ValueError(\"No paper provided for critique\")\n",
    "    \n",
    "    # Extract paper content from the last message\n",
    "    last_message = messages[-1]\n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        paper_content = last_message.content\n",
    "    else:\n",
    "        paper_content = str(last_message)\n",
    "    \n",
    "    # Extract title if provided in a specific format\n",
    "    paper_title = None\n",
    "    if paper_content.startswith(\"Title:\"):\n",
    "        lines = paper_content.split('\\n')\n",
    "        paper_title = lines[0].replace(\"Title:\", \"\").strip()\n",
    "    \n",
    "    return {\n",
    "        \"paper_content\": paper_content,\n",
    "        \"paper_title\": paper_title\n",
    "    }\n",
    "\n",
    "# ===== PARALLEL DIMENSION EVALUATION =====\n",
    "\n",
    "async def evaluate_dimensions(state: PaperCritiqueState) -> dict:\n",
    "    \"\"\"\n",
    "    Coordinate parallel evaluation of all PACT dimensions.\n",
    "    \n",
    "    This node spawns all dimension agents to work in parallel.\n",
    "    \"\"\"\n",
    "    # Run all dimension critiques in parallel\n",
    "    import asyncio\n",
    "    \n",
    "    tasks = [\n",
    "        critique_research_foundations(state),\n",
    "        critique_methodological_rigor(state),\n",
    "        critique_structure_coherence(state),\n",
    "        critique_academic_precision(state),\n",
    "        critique_critical_sophistication(state)\n",
    "    ]\n",
    "    \n",
    "    # Wait for all tasks to complete\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Combine all dimension critiques\n",
    "    combined_critiques = {}\n",
    "    for result in results:\n",
    "        if 'dimension_critiques' in result:\n",
    "            combined_critiques.update(result['dimension_critiques'])\n",
    "    \n",
    "    return {\"dimension_critiques\": combined_critiques}\n",
    "\n",
    "# ===== GRAPH CONSTRUCTION =====\n",
    "\n",
    "def build_pact_critique_graph():\n",
    "    \"\"\"\n",
    "    Build the complete PACT critique workflow graph.\n",
    "    \"\"\"\n",
    "    # Create the workflow\n",
    "    workflow = StateGraph(PaperCritiqueState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"process_input\", process_paper_input)\n",
    "    workflow.add_node(\"plan_critique\", plan_critique)\n",
    "    workflow.add_node(\"evaluate_dimensions\", evaluate_dimensions)\n",
    "    workflow.add_node(\"synthesize_critique\", synthesize_critique)\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(START, \"process_input\")\n",
    "    workflow.add_edge(\"process_input\", \"plan_critique\")\n",
    "    # plan_critique uses Command to go to evaluate_dimensions\n",
    "    workflow.add_edge(\"evaluate_dimensions\", \"synthesize_critique\")\n",
    "    workflow.add_edge(\"synthesize_critique\", END)\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# Compile the workflow\n",
    "pact_critique_builder = build_pact_critique_graph()\n",
    "pact_critique_agent = pact_critique_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the PACT Critique System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and visualize the workflow\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from pact.pact_critique_agent import pact_critique_builder\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "pact_agent = pact_critique_builder.compile(checkpointer=checkpointer)\n",
    "display(Image(pact_agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample paper excerpt\n",
    "sample_paper = \"\"\"\n",
    "Title: The Impact of Social Media on Academic Performance: A Mixed Methods Study\n",
    "\n",
    "Abstract:\n",
    "This study examines the relationship between social media usage and academic performance among \n",
    "undergraduate students. Using surveys and interviews with 200 students, we found that excessive \n",
    "social media use correlates with lower GPA scores. However, educational use of social media \n",
    "platforms showed positive effects on collaborative learning.\n",
    "\n",
    "Introduction:\n",
    "Social media has become ubiquitous in student life. Many educators worry about its impact on \n",
    "academic performance. This study investigates whether these concerns are justified. Previous \n",
    "research has shown mixed results, with some studies finding negative correlations and others \n",
    "finding no significant relationship. Our research aims to clarify these conflicting findings.\n",
    "\n",
    "Literature Review:\n",
    "Smith (2020) found that students who spend more than 3 hours daily on social media have lower \n",
    "grades. Jones et al. (2019) argued that the type of social media use matters more than duration. \n",
    "Educational platforms like LinkedIn showed different patterns than entertainment-focused platforms \n",
    "like TikTok. However, these studies used different methodologies, making comparisons difficult.\n",
    "\n",
    "Methodology:\n",
    "We surveyed 200 undergraduate students about their social media habits and collected their GPA \n",
    "data. Additionally, we conducted 20 in-depth interviews to understand usage patterns. The survey \n",
    "included questions about daily usage time, platform preferences, and purposes of use.\n",
    "\n",
    "Results:\n",
    "Students using social media for more than 4 hours daily had an average GPA of 2.8, compared to \n",
    "3.2 for those using it less than 2 hours. However, students who used educational features had \n",
    "higher engagement scores in group projects.\n",
    "\n",
    "Discussion:\n",
    "Our findings suggest a nuanced relationship between social media and academic performance. While \n",
    "excessive recreational use appears detrimental, educational applications show promise. Universities \n",
    "should consider developing guidelines that encourage productive social media use.\n",
    "\n",
    "Conclusion:\n",
    "Social media's impact on academic performance depends on how it's used. Future research should \n",
    "explore interventions that promote beneficial usage patterns while minimizing distractions.\n",
    "\"\"\"\n",
    "\n",
    "# Run the critique\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"test_paper_1\", \"recursion_limit\": 30}}\n",
    "result = await pact_agent.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=sample_paper)]}, \n",
    "    config=thread\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final critique\n",
    "from rich.markdown import Markdown\n",
    "if 'final_critique' in result:\n",
    "    display(Markdown(result['final_critique']))\n",
    "    print(f\"\\nOverall Score: {result.get('overall_score', 'N/A')}/100\")\n",
    "else:\n",
    "    print(\"Critique not yet complete. Check state:\", result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features: File Upload and Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/pact/pact_file_processor.py\n",
    "\n",
    "\"\"\"\n",
    "File Processing Utilities for PACT Critique System\n",
    "\n",
    "Handles various file formats for paper submission.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import PyPDF2\n",
    "import docx\n",
    "\n",
    "def read_paper_from_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Read paper content from various file formats.\n",
    "    \n",
    "    Supports: .txt, .pdf, .docx, .md\n",
    "    \"\"\"\n",
    "    path = Path(file_path)\n",
    "    \n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    extension = path.suffix.lower()\n",
    "    \n",
    "    if extension == '.txt' or extension == '.md':\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    \n",
    "    elif extension == '.pdf':\n",
    "        text = \"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "    \n",
    "    elif extension == '.docx':\n",
    "        doc = docx.Document(path)\n",
    "        return '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {extension}\")\n",
    "\n",
    "def save_critique_to_file(critique: str, output_path: str, format: str = 'md') -> str:\n",
    "    \"\"\"\n",
    "    Save critique to file in specified format.\n",
    "    \"\"\"\n",
    "    path = Path(output_path)\n",
    "    \n",
    "    if format == 'md':\n",
    "        path = path.with_suffix('.md')\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            f.write(critique)\n",
    "    \n",
    "    elif format == 'txt':\n",
    "        path = path.with_suffix('.txt')\n",
    "        # Convert markdown to plain text (basic conversion)\n",
    "        plain_text = critique.replace('#', '').replace('*', '').replace('_', '')\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            f.write(plain_text)\n",
    "    \n",
    "    elif format == 'html':\n",
    "        path = path.with_suffix('.html')\n",
    "        import markdown\n",
    "        html_content = markdown.markdown(critique)\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>PACT Critique Report</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}\n",
    "        h1 {{ color: #333; }}\n",
    "        h2 {{ color: #666; }}\n",
    "        h3 {{ color: #888; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "{html_content}\n",
    "</body>\n",
    "</html>\"\"\")\n",
    "    \n",
    "    return str(path)\n",
    "\n",
    "async def critique_paper_file(file_path: str, output_dir: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Critique a paper from a file and save results.\n",
    "    \"\"\"\n",
    "    from pact.pact_critique_agent import pact_critique_agent\n",
    "    from langchain_core.messages import HumanMessage\n",
    "    \n",
    "    # Read paper content\n",
    "    paper_content = read_paper_from_file(file_path)\n",
    "    \n",
    "    # Run critique\n",
    "    result = await pact_critique_agent.ainvoke(\n",
    "        {\"messages\": [HumanMessage(content=paper_content)]}\n",
    "    )\n",
    "    \n",
    "    # Save critique if output directory specified\n",
    "    if output_dir and 'final_critique' in result:\n",
    "        output_path = Path(output_dir) / f\"{Path(file_path).stem}_critique\"\n",
    "        saved_path = save_critique_to_file(\n",
    "            result['final_critique'], \n",
    "            str(output_path), \n",
    "            format='md'\n",
    "        )\n",
    "        print(f\"Critique saved to: {saved_path}\")\n",
    "    \n",
    "    return result.get('final_critique', 'Critique generation failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process a paper from file\n",
    "# Uncomment and modify path as needed\n",
    "\"\"\"\n",
    "from pact.pact_file_processor import critique_paper_file\n",
    "\n",
    "# Critique a paper from a file\n",
    "critique = await critique_paper_file(\n",
    "    file_path=\"path/to/student_paper.pdf\",\n",
    "    output_dir=\"critique_reports/\"\n",
    ")\n",
    "\n",
    "print(\"Critique generated successfully!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple CLI interface\n",
    "%%writefile ../src/pact/pact_cli.py\n",
    "\n",
    "\"\"\"\n",
    "Command-line interface for PACT Critique System\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "async def main():\n",
    "    parser = argparse.ArgumentParser(description='PACT Academic Paper Critique System')\n",
    "    parser.add_argument('input_file', help='Path to the paper file to critique')\n",
    "    parser.add_argument('-o', '--output', help='Output directory for critique report')\n",
    "    parser.add_argument('-f', '--format', choices=['md', 'txt', 'html'], \n",
    "                       default='md', help='Output format for critique')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(f\"Processing paper: {args.input_file}\")\n",
    "    print(\"This may take a few minutes...\")\n",
    "    \n",
    "    from pact.pact_file_processor import critique_paper_file\n",
    "    \n",
    "    try:\n",
    "        critique = await critique_paper_file(\n",
    "            file_path=args.input_file,\n",
    "            output_dir=args.output\n",
    "        )\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Critique Complete!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if not args.output:\n",
    "            print(\"\\n\" + critique)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has created a comprehensive PACT-based multi-agent critique system that:\n",
    "\n",
    "1. **Loads and parses the PACT taxonomy** from the provided PACT_JSON.docx file\n",
    "2. **Implements 5 specialized agents**, each focused on one PACT dimension\n",
    "3. **Uses a supervisor agent** to coordinate the critique and synthesize feedback\n",
    "4. **Provides structured, actionable feedback** with scores and recommendations\n",
    "5. **Supports multiple file formats** for paper input (PDF, DOCX, TXT, MD)\n",
    "6. **Generates formatted reports** in multiple output formats\n",
    "\n",
    "The system can be:\n",
    "- Used interactively in this notebook\n",
    "- Deployed as a web service using LangGraph\n",
    "- Run from the command line using the CLI interface\n",
    "- Integrated into existing academic workflows\n",
    "\n",
    "The modular design allows for easy customization and extension, such as:\n",
    "- Adding more specialized agents for specific paper types\n",
    "- Customizing rubrics for different academic levels\n",
    "- Integrating with learning management systems\n",
    "- Adding batch processing capabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}